{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !kaggle competitions download -c shopee-product-matching\n",
    "# !unzip shopee-product-matching.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!{sys.executable} -m pip uninstall timm -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preliminaries\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import random\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Visuals and CV2\n",
    "import cv2\n",
    "\n",
    "# albumentations for augs\n",
    "import albumentations\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#torch\n",
    "import torch\n",
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Parameter\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, CosineAnnealingLR, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "DIM = (224, 224)\n",
    "\n",
    "NUM_WORKERS = 16\n",
    "TRAIN_BATCH_SIZE = 4\n",
    "VALID_BATCH_SIZE = 4\n",
    "EPOCHS = 100\n",
    "SEED = 2020\n",
    "LR = 1e-3\n",
    "\n",
    "device = torch.device('cuda')\n",
    "\n",
    "\n",
    "################################################# MODEL ####################################################################\n",
    "\n",
    "model_name = 'swin_small_patch4_window7_224' #efficientnet_b0-b7\n",
    "\n",
    "################################################ Metric Loss and its params #######################################################\n",
    "loss_module = 'arcface' #'cosface' #'adacos'\n",
    "s = 30.0\n",
    "m = 0.5 \n",
    "ls_eps = 0.0\n",
    "easy_margin = False\n",
    "\n",
    "\n",
    "####################################### Scheduler and its params ############################################################\n",
    "SCHEDULER = 'CosineAnnealingWarmRestarts' #'CosineAnnealingLR'\n",
    "#SCHEDULER = 'ReduceLROnPlateau'\n",
    "factor=0.2 # ReduceLROnPlateau\n",
    "patience=3 # ReduceLROnPlateau\n",
    "eps=1e-6 # ReduceLROnPlateau\n",
    "T_max=10 # CosineAnnealingLR\n",
    "T_0=7 # CosineAnnealingWarmRestarts\n",
    "min_lr=1e-6\n",
    "\n",
    "############################################## Model Params ###############################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_torch(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "seed_torch(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "    \n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "    \n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_scheduler(optimizer):\n",
    "    if SCHEDULER =='ReduceLROnPlateau':\n",
    "        scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=factor, patience=patience, verbose=True, eps=eps)\n",
    "    elif SCHEDULER =='CosineAnnealingLR':\n",
    "        scheduler = CosineAnnealingLR(optimizer, T_max=T_max, eta_min=min_lr, last_epoch=-1)\n",
    "    elif SCHEDULER =='CosineAnnealingWarmRestarts':\n",
    "        scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=T_0, T_mult=1, eta_min=min_lr, last_epoch=-1)\n",
    "    return scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.modules.loss._WeightedLoss):\n",
    "    def __init__(self, weight=None, gamma=2,reduction='mean'):\n",
    "        super(FocalLoss, self).__init__(weight,reduction=reduction)\n",
    "        self.gamma = gamma\n",
    "        self.weight = weight #weight parameter will act as the alpha parameter to balance class weights\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        ce_loss = F.cross_entropy(input, target,reduction=self.reduction,weight=self.weight)\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        focal_loss = ((1 - pt) ** self.gamma * ce_loss).mean()\n",
    "        return focal_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_loss():\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "#     loss = FocalLoss()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_train_transforms():\n",
    "#     return albumentations.Compose(\n",
    "#         [   \n",
    "#             albumentations.Resize(DIM[0],DIM[1],always_apply=True),\n",
    "#             albumentations.HorizontalFlip(p=0.5),\n",
    "#             albumentations.VerticalFlip(p=0.5),\n",
    "#             albumentations.Rotate(limit=120, p=0.8),\n",
    "#             albumentations.RandomBrightness(limit=(0.09, 0.6), p=0.5),\n",
    "#             albumentations.Cutout(num_holes=8, max_h_size=4, max_w_size=4, fill_value=0, always_apply=False, p=0.5),\n",
    "# #             albumentations.ShiftScaleRotate(\n",
    "# #                shift_limit=0.25, scale_limit=0.1, rotate_limit=0\n",
    "# #             ),\n",
    "#             albumentations.Normalize(),\n",
    "#             ToTensorV2(p=1.0),\n",
    "#         ]\n",
    "#     )\n",
    "\n",
    "\n",
    "from albumentations import (\n",
    "    HorizontalFlip, IAAPerspective, ShiftScaleRotate, CLAHE, RandomRotate90,\n",
    "    Transpose, ShiftScaleRotate, Blur, OpticalDistortion, GridDistortion, HueSaturationValue,\n",
    "    IAAAdditiveGaussianNoise, GaussNoise, MotionBlur, MedianBlur, IAAPiecewiseAffine,\n",
    "    IAASharpen, IAAEmboss, RandomContrast, RandomBrightness, Flip, OneOf, Compose, RandomGamma, ElasticTransform, ChannelShuffle,RGBShift, Rotate\n",
    ")\n",
    "\n",
    "def get_train_transforms():\n",
    "    return Compose([\n",
    "        albumentations.Resize(DIM[0],DIM[1],always_apply=True),\n",
    "        RandomRotate90(),\n",
    "        Flip(),\n",
    "        Transpose(),\n",
    "        OneOf([\n",
    "            IAAAdditiveGaussianNoise(),\n",
    "            GaussNoise(),\n",
    "        ], p=0.2),\n",
    "        OneOf([\n",
    "            MotionBlur(p=.2),\n",
    "            MedianBlur(blur_limit=3, p=.1),\n",
    "            Blur(blur_limit=3, p=.1),\n",
    "        ], p=0.2),\n",
    "        ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.2, rotate_limit=45, p=.2),\n",
    "        OneOf([\n",
    "            OpticalDistortion(p=0.3),\n",
    "            GridDistortion(p=.1),\n",
    "            IAAPiecewiseAffine(p=0.3),\n",
    "        ], p=0.2),\n",
    "        OneOf([\n",
    "            CLAHE(clip_limit=2),\n",
    "            IAASharpen(),\n",
    "            IAAEmboss(),\n",
    "            RandomContrast(),\n",
    "            RandomBrightness(),\n",
    "        ], p=0.3),\n",
    "        albumentations.Normalize(),\n",
    "        ToTensorV2(p=1.0),\n",
    "        #HueSaturationValue(p=0.3),\n",
    "    ]\n",
    "    )\n",
    "\n",
    "def get_valid_transforms():\n",
    "\n",
    "    return albumentations.Compose(\n",
    "        [\n",
    "            albumentations.Resize(DIM[0],DIM[1],always_apply=True),\n",
    "            albumentations.Normalize(),\n",
    "        ToTensorV2(p=1.0)\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmac(x, L=3, eps=1e-6):\n",
    "    ovr = 0.4 # desired overlap of neighboring regions\n",
    "    steps = torch.Tensor([2, 3, 4, 5, 6, 7]) # possible regions for the long dimension\n",
    "\n",
    "    W = x.size(3)\n",
    "    H = x.size(2)\n",
    "\n",
    "    w = min(W, H)\n",
    "    w2 = math.floor(w/2.0 - 1)\n",
    "\n",
    "    b = (max(H, W)-w)/(steps-1)\n",
    "    (tmp, idx) = torch.min(torch.abs(((w**2 - w*b)/w**2)-ovr), 0) # steps(idx) regions for long dimension\n",
    "\n",
    "    # region overplus per dimension\n",
    "    Wd = 0;\n",
    "    Hd = 0;\n",
    "    if H < W:  \n",
    "        Wd = idx.item() + 1\n",
    "    elif H > W:\n",
    "        Hd = idx.item() + 1\n",
    "\n",
    "    v = F.max_pool2d(x, (x.size(-2), x.size(-1)))\n",
    "    v = v / (torch.norm(v, p=2, dim=1, keepdim=True) + eps).expand_as(v)\n",
    "\n",
    "    for l in range(1, L+1):\n",
    "        wl = math.floor(2*w/(l+1))\n",
    "        wl2 = math.floor(wl/2 - 1)\n",
    "\n",
    "        if l+Wd == 1:\n",
    "            b = 0\n",
    "        else:\n",
    "            b = (W-wl)/(l+Wd-1)\n",
    "        cenW = torch.floor(wl2 + torch.Tensor(range(l-1+Wd+1))*b) - wl2 # center coordinates\n",
    "        if l+Hd == 1:\n",
    "            b = 0\n",
    "        else:\n",
    "            b = (H-wl)/(l+Hd-1)\n",
    "        cenH = torch.floor(wl2 + torch.Tensor(range(l-1+Hd+1))*b) - wl2 # center coordinates\n",
    "            \n",
    "        for i_ in cenH.tolist():\n",
    "            for j_ in cenW.tolist():\n",
    "                if wl == 0:\n",
    "                    continue\n",
    "                R = x[:,:,(int(i_)+torch.Tensor(range(wl)).long()).tolist(),:]\n",
    "                R = R[:,:,:,(int(j_)+torch.Tensor(range(wl)).long()).tolist()]\n",
    "                vt = F.max_pool2d(R, (R.size(-2), R.size(-1)))\n",
    "                vt = vt / (torch.norm(vt, p=2, dim=1, keepdim=True) + eps).expand_as(vt)\n",
    "                v += vt\n",
    "\n",
    "    return v\n",
    "\n",
    "\n",
    "def gem(x, p=3, eps=1e-6):\n",
    "    return F.avg_pool2d(x.clamp(min=eps).pow(p), (x.size(-2), x.size(-1))).pow(1./p)\n",
    "    # return F.lp_pool2d(F.threshold(x, eps, eps), p, (x.size(-2), x.size(-1))) # alternative\n",
    "\n",
    "\n",
    "    \n",
    "class RMAC(nn.Module):\n",
    "\n",
    "    def __init__(self, L=3, eps=1e-6):\n",
    "        super(RMAC,self).__init__()\n",
    "        self.L = L\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        return rmac(x, L=self.L, eps=self.eps)\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(' + 'L=' + '{}'.format(self.L) + ')'\n",
    "    \n",
    "    \n",
    "class GeM(nn.Module):\n",
    "\n",
    "    def __init__(self, p=4, eps=1e-6):\n",
    "        super(GeM,self).__init__()\n",
    "        self.p = Parameter(torch.ones(1)*p)\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        return gem(x, p=self.p, eps=self.eps)\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(' + 'p=' + '{:.4f}'.format(self.p.data.tolist()[0]) + ', ' + 'eps=' + str(self.eps) + ')'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShopeeDataset(Dataset):\n",
    "    def __init__(self, csv, transforms=None):\n",
    "\n",
    "        self.csv = csv.reset_index()\n",
    "        self.augmentations = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.csv.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.csv.iloc[index]\n",
    "        \n",
    "        #text = row.title\n",
    "        \n",
    "        image = cv2.imread(row.filepath)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        if self.augmentations:\n",
    "            augmented = self.augmentations(image=image)\n",
    "            image = augmented['image']       \n",
    "        \n",
    "        \n",
    "        return image,torch.tensor(row.label_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShopeeNet(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                 n_classes,\n",
    "                 model_name='efficientnet_b0',\n",
    "#                  temperature=1,\n",
    "                 use_fc=False,\n",
    "                 fc_dim=512,\n",
    "                 dropout=0.0,\n",
    "                 loss_module='softmax',\n",
    "                 s=30.0,\n",
    "                 margin=0.50,\n",
    "                 ls_eps=0.0,\n",
    "                 theta_zero=0.785,\n",
    "                 pretrained=True):\n",
    "        \n",
    "        super(ShopeeNet, self).__init__()\n",
    "        print('Building Model Backbone for {} model'.format(model_name))\n",
    "        \n",
    "        self.backbone = timm.create_model(model_name, pretrained=pretrained)\n",
    "        if model_name.startswith('xception'):\n",
    "            final_in_features = self.backbone.fc.in_features\n",
    "            self.backbone.fc = nn.Identity()\n",
    "        if model_name.startswith('efficientnet'):\n",
    "            print(\"EFFNET\")\n",
    "            final_in_features = self.backbone.classifier.in_features\n",
    "            self.backbone.classifier = nn.Identity()\n",
    "        elif model_name.startswith('inception_resnet'):\n",
    "            print(\"INCEPTIONRESNET\")\n",
    "            final_in_features = self.backbone.classif.in_features\n",
    "            self.backbone.classif = nn.Identity()\n",
    "        elif 'nfnet' in model_name:\n",
    "            print(\"NFNET\")\n",
    "            final_in_features = self.backbone.head.fc.in_features\n",
    "            self.backbone.head = nn.Identity()\n",
    "        elif 'swin' in model_name:\n",
    "            print(\"SWIN\")\n",
    "            final_in_features = fc_dim\n",
    "            self.backbone.head = nn.Linear(self.backbone.head.in_features, fc_dim)\n",
    "            nn.init.xavier_normal_(self.backbone.head.weight)\n",
    "            nn.init.constant_(self.backbone.head.bias, 0)\n",
    "            use_fc = False\n",
    "        elif model_name.startswith('densenet'):\n",
    "            print(\"DENSENET\")\n",
    "            final_in_features = self.backbone.head.in_features\n",
    "            self.backbone.head = nn.Identity()\n",
    "        \n",
    "        self.backbone.global_pool = nn.Identity()\n",
    "#         self.temperature = nn.Parameter(torch.ones(1) * temperature)\n",
    "        \n",
    "#         self.rmac_pooling = RMAC()\n",
    "#         self.gem_pooling = GeM()\n",
    "        self.pooling =  nn.AdaptiveAvgPool2d(1)\n",
    "            \n",
    "        self.use_fc = use_fc\n",
    "        if use_fc:\n",
    "            self.dropout = nn.Dropout(p=dropout)\n",
    "            self.fc = nn.Linear(2*final_in_features, fc_dim)\n",
    "            self.bn1 = nn.BatchNorm2d(final_in_features)\n",
    "            self.bn2 = nn.BatchNorm1d(fc_dim)\n",
    "            self._init_params()\n",
    "            final_in_features = fc_dim\n",
    "\n",
    "        self.loss_module = loss_module\n",
    "        if loss_module == 'arcface':\n",
    "            self.final = ArcMarginProduct(final_in_features, n_classes,\n",
    "                                          s=s, m=margin, easy_margin=False, ls_eps=ls_eps)\n",
    "        elif loss_module == 'softmax':\n",
    "            self.final = nn.Linear(final_in_features, n_classes)\n",
    "\n",
    "    def _init_params(self):\n",
    "        nn.init.xavier_normal_(self.fc.weight)\n",
    "        nn.init.constant_(self.fc.bias, 0)\n",
    "        nn.init.constant_(self.bn1.weight, 1)\n",
    "        nn.init.constant_(self.bn1.bias, 0)\n",
    "        nn.init.constant_(self.bn2.weight, 1)\n",
    "        nn.init.constant_(self.bn2.bias, 0)\n",
    "\n",
    "    def forward(self, x, label):\n",
    "        feature = self.extract_feat(x)\n",
    "        if self.loss_module == 'arcface':\n",
    "            logits = self.final(feature, label)\n",
    "        else:\n",
    "            logits = self.final(feature)\n",
    "        return logits\n",
    "\n",
    "    def extract_feat(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        x = self.backbone(x)\n",
    "        print(x.size())\n",
    "#         x = self.bn1(x)\n",
    "        \n",
    "#         gem_x = self.gem_pooling(x).view(batch_size, -1)\n",
    "#         rmac_x = self.rmac_pooling(x).view(batch_size, -1)\n",
    "#         x = torch.cat([rmac_x, gem_x], axis=1)\n",
    "#         x = self.pooling(x).view(batch_size, -1)\n",
    "        if self.use_fc:\n",
    "            x = self.dropout(x)\n",
    "            x = self.fc(x)\n",
    "            x = self.bn2(x)\n",
    "            \n",
    "        x = F.normalize(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    def temperature_scale(self, logits):\n",
    "        \"\"\"\n",
    "        Perform temperature scaling on logits\n",
    "        \"\"\"\n",
    "        # Expand temperature to match the size of logits\n",
    "        temperature = self.temperature.unsqueeze(1).expand(logits.size(0), logits.size(1))\n",
    "        return logits / temperature\n",
    "\n",
    "    # This function probably should live outside of this class, but whatever\n",
    "    def set_temperature(self, valid_loader):\n",
    "        \"\"\"\n",
    "        Tune the tempearature of the model (using the validation set).\n",
    "        We're going to set it to optimize NLL.\n",
    "        valid_loader (DataLoader): validation set loader\n",
    "        \"\"\"\n",
    "        self.cuda()\n",
    "        nll_criterion = nn.CrossEntropyLoss().cuda()\n",
    "        ece_criterion = _ECELoss().cuda()\n",
    "\n",
    "        # First: collect all the logits and labels for the validation set\n",
    "        logits_list = []\n",
    "        labels_list = []\n",
    "        with torch.no_grad():\n",
    "            for input, label in valid_loader:\n",
    "                input = input.cuda()\n",
    "                logits = self.model(input)\n",
    "                logits_list.append(logits)\n",
    "                labels_list.append(label)\n",
    "            logits = torch.cat(logits_list).cuda()\n",
    "            labels = torch.cat(labels_list).cuda()\n",
    "\n",
    "        # Calculate NLL and ECE before temperature scaling\n",
    "        before_temperature_nll = nll_criterion(logits, labels).item()\n",
    "        before_temperature_ece = ece_criterion(logits, labels).item()\n",
    "        print('Before temperature - NLL: %.3f, ECE: %.3f' % (before_temperature_nll, before_temperature_ece))\n",
    "\n",
    "        # Next: optimize the temperature w.r.t. NLL\n",
    "        optimizer = optim.LBFGS([self.temperature], lr=0.01, max_iter=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArcMarginProduct(nn.Module):\n",
    "    r\"\"\"Implement of large margin arc distance: :\n",
    "        Args:\n",
    "            in_features: size of each input sample\n",
    "            out_features: size of each output sample\n",
    "            s: norm of input feature\n",
    "            m: margin\n",
    "            cos(theta + m)\n",
    "        \"\"\"\n",
    "    def __init__(self, in_features, out_features, s=30.0, m=0.50, easy_margin=False, ls_eps=0.0):\n",
    "        super(ArcMarginProduct, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.s = s\n",
    "        self.m = m\n",
    "        self.ls_eps = ls_eps  # label smoothing\n",
    "        self.weight = Parameter(torch.FloatTensor(out_features, in_features))\n",
    "        nn.init.xavier_uniform_(self.weight)\n",
    "\n",
    "        self.easy_margin = easy_margin\n",
    "        self.cos_m = math.cos(m)\n",
    "        self.sin_m = math.sin(m)\n",
    "        self.th = math.cos(math.pi - m)\n",
    "        self.mm = math.sin(math.pi - m) * m\n",
    "\n",
    "    def forward(self, input, label):\n",
    "        # --------------------------- cos(theta) & phi(theta) ---------------------------\n",
    "        cosine = F.linear(F.normalize(input), F.normalize(self.weight))\n",
    "        sine = torch.sqrt(1.0 - torch.pow(cosine, 2))\n",
    "        phi = cosine * self.cos_m - sine * self.sin_m\n",
    "        if self.easy_margin:\n",
    "            phi = torch.where(cosine > 0, phi, cosine)\n",
    "        else:\n",
    "            phi = torch.where(cosine > self.th, phi, cosine - self.mm)\n",
    "        # --------------------------- convert label to one-hot ---------------------------\n",
    "        # one_hot = torch.zeros(cosine.size(), requires_grad=True, device='cuda')\n",
    "        one_hot = torch.zeros(cosine.size(), device='cuda')\n",
    "        one_hot.scatter_(1, label.view(-1, 1).long(), 1)\n",
    "        if self.ls_eps > 0:\n",
    "            one_hot = (1 - self.ls_eps) * one_hot + self.ls_eps / self.out_features\n",
    "        # -------------torch.where(out_i = {x_i if condition_i else y_i) -------------\n",
    "        output = (one_hot * phi) + ((1.0 - one_hot) * cosine)\n",
    "        output *= self.s\n",
    "\n",
    "        return output\n",
    "    \n",
    "class _ECELoss(nn.Module):\n",
    "    def __init__(self, n_bins=15):\n",
    "        \"\"\"\n",
    "        n_bins (int): number of confidence interval bins\n",
    "        \"\"\"\n",
    "        super(_ECELoss, self).__init__()\n",
    "        bin_boundaries = torch.linspace(0, 1, n_bins + 1)\n",
    "        self.bin_lowers = bin_boundaries[:-1]\n",
    "        self.bin_uppers = bin_boundaries[1:]\n",
    "\n",
    "    def forward(self, logits, labels):\n",
    "        softmaxes = F.softmax(logits, dim=1)\n",
    "        confidences, predictions = torch.max(softmaxes, 1)\n",
    "        accuracies = predictions.eq(labels)\n",
    "\n",
    "        ece = torch.zeros(1, device=logits.device)\n",
    "        for bin_lower, bin_upper in zip(self.bin_lowers, self.bin_uppers):\n",
    "            # Calculated |confidence - accuracy| in each bin\n",
    "            in_bin = confidences.gt(bin_lower.item()) * confidences.le(bin_upper.item())\n",
    "            prop_in_bin = in_bin.float().mean()\n",
    "            if prop_in_bin.item() > 0:\n",
    "                accuracy_in_bin = accuracies[in_bin].float().mean()\n",
    "                avg_confidence_in_bin = confidences[in_bin].mean()\n",
    "                ece += torch.abs(avg_confidence_in_bin - accuracy_in_bin) * prop_in_bin\n",
    "\n",
    "        return ece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fn(dataloader,model,criterion,optimizer,device,scheduler,epoch):\n",
    "    model.train()\n",
    "    loss_score = AverageMeter()\n",
    "    \n",
    "    tk0 = tqdm(enumerate(dataloader), total=len(dataloader))\n",
    "    for bi,d in tk0:\n",
    "        \n",
    "        batch_size = d[0].shape[0]\n",
    "\n",
    "\n",
    "        images = d[0]\n",
    "        targets = d[1]\n",
    "\n",
    "        images = images.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(images,targets)\n",
    "        \n",
    "        loss = criterion(output,targets)\n",
    "        \n",
    "        loss.mean().backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        loss_score.update(loss.detach().item(), batch_size)\n",
    "        tk0.set_postfix(Train_Loss=loss_score.avg,Epoch=epoch,LR=optimizer.param_groups[0]['lr'])\n",
    "        \n",
    "    if scheduler is not None:\n",
    "            scheduler.step()\n",
    "        \n",
    "    return loss_score\n",
    "\n",
    "\n",
    "def eval_fn(data_loader,model,criterion,device,scheduler):\n",
    "    \n",
    "    loss_score = AverageMeter()\n",
    "    \n",
    "    model.eval()\n",
    "    tk0 = tqdm(enumerate(data_loader), total=len(data_loader))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for bi,d in tk0:\n",
    "            batch_size = d[0].size()[0]\n",
    "\n",
    "            image = d[0]\n",
    "            targets = d[1]\n",
    "\n",
    "            image = image.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            output = model(image,targets)\n",
    "\n",
    "            loss = criterion(output,targets)\n",
    "            \n",
    "            loss_score.update(loss.mean().detach().item(), batch_size)\n",
    "            tk0.set_postfix(Eval_Loss=loss_score.avg)\n",
    "            \n",
    "#         if scheduler is not None:\n",
    "#             scheduler.step(loss.detach().item())\n",
    "            \n",
    "    return loss_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('folds.csv')\n",
    "data['filepath'] = data['image'].apply(lambda x: os.path.join('train_images', x))\n",
    "# data = pd.read_csv('data_plus_ozon_folds.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "data['label_group'] = encoder.fit_transform(data['label_group'])\n",
    "\n",
    "# labels = data.label_group.unique()\n",
    "# train_labels = np.random.choice(labels, int(0.8*len(labels)))\n",
    "# train, valid = train_test_split(data, shuffle = True, random_state = 2020)\n",
    "# train = train.reset_index(drop=True)\n",
    "# valid = valid.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {\n",
    "    'n_classes':11014,\n",
    "    'model_name':model_name,\n",
    "#     'temperature': 2,\n",
    "    'use_fc':True,\n",
    "    'fc_dim':512,\n",
    "    'dropout':0.0,\n",
    "    'loss_module':'arcface',\n",
    "    's':30.0,\n",
    "    'margin':0.50,\n",
    "    'ls_eps':0.0,\n",
    "    'theta_zero':0.785,\n",
    "    'pretrained':True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(use_checkpoint=False):\n",
    "        \n",
    "#     train = data[data['fold']!=0].reset_index(drop=True)\n",
    "#     train = data.reset_index(drop=True)\n",
    "#     valid = data[data['fold']==0].reset_index(drop=True)\n",
    "    train, valid = train_test_split(data, test_size=0.05, random_state=42)\n",
    "    train = train.reset_index(drop=True)\n",
    "    valid = valid.reset_index(drop=True)\n",
    "    \n",
    "\n",
    "#     train = data[data.label_group.isin(train_labels)].reset_index(drop=True)\n",
    "#     valid = data[~data.label_group.isin(train_labels)].reset_index(drop=True)\n",
    "    # Defining DataSet\n",
    "    train_dataset = ShopeeDataset(\n",
    "        csv=train,\n",
    "        transforms=get_train_transforms(),\n",
    "    )\n",
    "        \n",
    "    valid_dataset = ShopeeDataset(\n",
    "        csv=valid,\n",
    "        transforms=get_valid_transforms(),\n",
    "    )\n",
    "        \n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=TRAIN_BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        pin_memory=True,\n",
    "        drop_last=True,\n",
    "        num_workers=NUM_WORKERS\n",
    "    )\n",
    "    \n",
    "    valid_loader = torch.utils.data.DataLoader(\n",
    "        valid_dataset,\n",
    "        batch_size=VALID_BATCH_SIZE,\n",
    "        num_workers=NUM_WORKERS,\n",
    "        shuffle=False,\n",
    "        pin_memory=True,\n",
    "        drop_last=False,\n",
    "    )\n",
    "    \n",
    "    # Defining Device\n",
    "    device = torch.device(\"cuda\")\n",
    "    \n",
    "    # Defining Model for specific fold\n",
    "    model = ShopeeNet(**model_params)\n",
    "    if use_checkpoint:\n",
    "        print(\"LOADING MODEL...\")\n",
    "        model.load_state_dict(torch.load('model_eca_nfnet_l0_IMG_SIZE_512_arcface_6.268_FullData_8GPUS.bin'))\n",
    "    \n",
    "    model.to(device)\n",
    "    \n",
    "    parallel_model = torch.nn.DataParallel(model)\n",
    "    \n",
    "#     for name, param in model.named_parameters():\n",
    "#         if name.startswith('backbone'):\n",
    "#             param.requires_grad = False \n",
    "    \n",
    "    \n",
    "    #DEfining criterion\n",
    "    criterion = fetch_loss()\n",
    "    criterion.to(device)\n",
    "        \n",
    "    # Defining Optimizer with weight decay to params other than bias and layer norms\n",
    "    param_optimizer = list(parallel_model.named_parameters())\n",
    "    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
    "    optimizer_parameters = [\n",
    "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.001},\n",
    "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0},\n",
    "            ]  \n",
    "    \n",
    "    optimizer = torch.optim.Adam(optimizer_parameters, lr=LR)\n",
    "    \n",
    "    #Defining LR SCheduler\n",
    "    scheduler = fetch_scheduler(optimizer)\n",
    "        \n",
    "    # THE ENGINE LOOP\n",
    "    best_loss = 10000\n",
    "    for epoch in range(EPOCHS):\n",
    "        train_loss = train_fn(train_loader, parallel_model, criterion, optimizer, device,scheduler=scheduler,epoch=epoch)\n",
    "        \n",
    "        valid_loss = eval_fn(valid_loader, parallel_model, criterion,device,scheduler=scheduler)\n",
    "        if valid_loss.avg < best_loss:\n",
    "            best_loss = valid_loss.avg\n",
    "            torch.save(parallel_model.module.state_dict(),f'SWINTRANS_{DIM[0]}_{loss_module}_{best_loss:.3f}_RMAC_GEM.bin')\n",
    "            print('best model found for epoch {}'.format(epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Model Backbone for swin_small_patch4_window7_224 model\n",
      "SWIN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/8134 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/8134 [00:00<?, ?it/s, Epoch=0, LR=0.001, Train_Loss=23.6]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 1/8134 [00:00<54:07,  2.50it/s, Epoch=0, LR=0.001, Train_Loss=23.6]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 1/8134 [00:00<54:07,  2.50it/s, Epoch=0, LR=0.001, Train_Loss=24.4]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 2/8134 [00:00<45:09,  3.00it/s, Epoch=0, LR=0.001, Train_Loss=24.4]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 512])\n",
      "torch.Size([4, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 2/8134 [00:00<45:09,  3.00it/s, Epoch=0, LR=0.001, Train_Loss=24.9]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 3/8134 [00:00<36:57,  3.67it/s, Epoch=0, LR=0.001, Train_Loss=24.9]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 3/8134 [00:00<36:57,  3.67it/s, Epoch=0, LR=0.001, Train_Loss=24.7]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 4/8134 [00:00<30:47,  4.40it/s, Epoch=0, LR=0.001, Train_Loss=24.7]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 4/8134 [00:00<30:47,  4.40it/s, Epoch=0, LR=0.001, Train_Loss=24.8]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 5/8134 [00:00<26:23,  5.13it/s, Epoch=0, LR=0.001, Train_Loss=24.8]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 512])\n",
      "torch.Size([4, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 5/8134 [00:01<26:23,  5.13it/s, Epoch=0, LR=0.001, Train_Loss=24.7]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 6/8134 [00:01<23:30,  5.76it/s, Epoch=0, LR=0.001, Train_Loss=24.7]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 6/8134 [00:01<23:30,  5.76it/s, Epoch=0, LR=0.001, Train_Loss=24.6]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 512])\n",
      "torch.Size([4, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 7/8134 [00:01<21:17,  6.36it/s, Epoch=0, LR=0.001, Train_Loss=24.6]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 7/8134 [00:01<21:17,  6.36it/s, Epoch=0, LR=0.001, Train_Loss=24.6]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 8/8134 [00:01<19:42,  6.87it/s, Epoch=0, LR=0.001, Train_Loss=24.6]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 8/8134 [00:01<19:42,  6.87it/s, Epoch=0, LR=0.001, Train_Loss=24.6]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 512])\n",
      "torch.Size([4, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 9/8134 [00:01<18:48,  7.20it/s, Epoch=0, LR=0.001, Train_Loss=24.6]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 9/8134 [00:01<18:48,  7.20it/s, Epoch=0, LR=0.001, Train_Loss=24.6]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 10/8134 [00:01<17:57,  7.54it/s, Epoch=0, LR=0.001, Train_Loss=24.6]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 10/8134 [00:01<17:57,  7.54it/s, Epoch=0, LR=0.001, Train_Loss=24.6]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 11/8134 [00:01<17:22,  7.79it/s, Epoch=0, LR=0.001, Train_Loss=24.6]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 512])\n",
      "torch.Size([4, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 11/8134 [00:01<17:22,  7.79it/s, Epoch=0, LR=0.001, Train_Loss=24.5]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 12/8134 [00:01<17:09,  7.89it/s, Epoch=0, LR=0.001, Train_Loss=24.5]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 512])\n",
      "torch.Size([4, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 12/8134 [00:01<17:09,  7.89it/s, Epoch=0, LR=0.001, Train_Loss=24.5]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 13/8134 [00:01<16:52,  8.02it/s, Epoch=0, LR=0.001, Train_Loss=24.5]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 13/8134 [00:02<16:52,  8.02it/s, Epoch=0, LR=0.001, Train_Loss=24.5]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 14/8134 [00:02<16:38,  8.13it/s, Epoch=0, LR=0.001, Train_Loss=24.5]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 512])\n",
      "torch.Size([4, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 14/8134 [00:02<16:38,  8.13it/s, Epoch=0, LR=0.001, Train_Loss=24.4]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 15/8134 [00:02<16:43,  8.09it/s, Epoch=0, LR=0.001, Train_Loss=24.4]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 15/8134 [00:02<16:43,  8.09it/s, Epoch=0, LR=0.001, Train_Loss=24.5]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 16/8134 [00:02<16:31,  8.19it/s, Epoch=0, LR=0.001, Train_Loss=24.5]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 16/8134 [00:02<16:31,  8.19it/s, Epoch=0, LR=0.001, Train_Loss=24.5]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 17/8134 [00:02<16:22,  8.26it/s, Epoch=0, LR=0.001, Train_Loss=24.5]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 512])\n",
      "torch.Size([4, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 17/8134 [00:02<16:22,  8.26it/s, Epoch=0, LR=0.001, Train_Loss=24.5]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 18/8134 [00:02<16:26,  8.22it/s, Epoch=0, LR=0.001, Train_Loss=24.5]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 18/8134 [00:02<16:26,  8.22it/s, Epoch=0, LR=0.001, Train_Loss=24.5]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 19/8134 [00:02<16:16,  8.31it/s, Epoch=0, LR=0.001, Train_Loss=24.5]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 512])\n",
      "torch.Size([4, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 19/8134 [00:02<16:16,  8.31it/s, Epoch=0, LR=0.001, Train_Loss=24.5]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 20/8134 [00:02<16:12,  8.34it/s, Epoch=0, LR=0.001, Train_Loss=24.5]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 512])\n",
      "torch.Size([4, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 20/8134 [00:02<16:12,  8.34it/s, Epoch=0, LR=0.001, Train_Loss=24.4]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 21/8134 [00:02<16:42,  8.09it/s, Epoch=0, LR=0.001, Train_Loss=24.4]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 21/8134 [00:03<16:42,  8.09it/s, Epoch=0, LR=0.001, Train_Loss=24.4]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 22/8134 [00:03<16:59,  7.96it/s, Epoch=0, LR=0.001, Train_Loss=24.4]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 512])\n",
      "torch.Size([4, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 22/8134 [00:03<16:59,  7.96it/s, Epoch=0, LR=0.001, Train_Loss=24.4]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 23/8134 [00:03<17:06,  7.90it/s, Epoch=0, LR=0.001, Train_Loss=24.4]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 23/8134 [00:03<17:06,  7.90it/s, Epoch=0, LR=0.001, Train_Loss=24.4]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 24/8134 [00:03<17:36,  7.67it/s, Epoch=0, LR=0.001, Train_Loss=24.4]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 512])\n",
      "torch.Size([4, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 24/8134 [00:03<17:36,  7.67it/s, Epoch=0, LR=0.001, Train_Loss=24.4]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 25/8134 [00:03<17:31,  7.71it/s, Epoch=0, LR=0.001, Train_Loss=24.4]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 25/8134 [00:03<17:31,  7.71it/s, Epoch=0, LR=0.001, Train_Loss=24.5]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 26/8134 [00:03<17:14,  7.84it/s, Epoch=0, LR=0.001, Train_Loss=24.5]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 26/8134 [00:03<17:14,  7.84it/s, Epoch=0, LR=0.001, Train_Loss=24.5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 512])\n",
      "torch.Size([4, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 27/8134 [00:03<16:57,  7.97it/s, Epoch=0, LR=0.001, Train_Loss=24.5]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 27/8134 [00:03<16:57,  7.97it/s, Epoch=0, LR=0.001, Train_Loss=24.5]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 28/8134 [00:03<16:46,  8.06it/s, Epoch=0, LR=0.001, Train_Loss=24.5]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 28/8134 [00:03<16:46,  8.06it/s, Epoch=0, LR=0.001, Train_Loss=24.6]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 29/8134 [00:03<16:34,  8.15it/s, Epoch=0, LR=0.001, Train_Loss=24.6]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 512])\n",
      "torch.Size([4, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 29/8134 [00:04<16:34,  8.15it/s, Epoch=0, LR=0.001, Train_Loss=24.6]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 30/8134 [00:04<16:30,  8.18it/s, Epoch=0, LR=0.001, Train_Loss=24.6]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 512])\n",
      "torch.Size([4, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 30/8134 [00:04<16:30,  8.18it/s, Epoch=0, LR=0.001, Train_Loss=24.5]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 31/8134 [00:04<16:27,  8.20it/s, Epoch=0, LR=0.001, Train_Loss=24.5]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 31/8134 [00:04<16:27,  8.20it/s, Epoch=0, LR=0.001, Train_Loss=24.5]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 32/8134 [00:04<16:27,  8.20it/s, Epoch=0, LR=0.001, Train_Loss=24.5]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 512])\n",
      "torch.Size([4, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 32/8134 [00:04<16:27,  8.20it/s, Epoch=0, LR=0.001, Train_Loss=24.5]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 33/8134 [00:04<16:35,  8.14it/s, Epoch=0, LR=0.001, Train_Loss=24.5]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 33/8134 [00:04<16:35,  8.14it/s, Epoch=0, LR=0.001, Train_Loss=24.5]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 34/8134 [00:04<16:32,  8.16it/s, Epoch=0, LR=0.001, Train_Loss=24.5]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 34/8134 [00:04<16:32,  8.16it/s, Epoch=0, LR=0.001, Train_Loss=24.5]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 35/8134 [00:04<16:24,  8.23it/s, Epoch=0, LR=0.001, Train_Loss=24.5]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 512])\n",
      "torch.Size([4, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 35/8134 [00:04<16:24,  8.23it/s, Epoch=0, LR=0.001, Train_Loss=24.5]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 36/8134 [00:04<16:28,  8.19it/s, Epoch=0, LR=0.001, Train_Loss=24.5]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 512])\n",
      "torch.Size([4, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 36/8134 [00:04<16:28,  8.19it/s, Epoch=0, LR=0.001, Train_Loss=24.5]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 37/8134 [00:04<16:30,  8.17it/s, Epoch=0, LR=0.001, Train_Loss=24.5]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 37/8134 [00:05<16:30,  8.17it/s, Epoch=0, LR=0.001, Train_Loss=24.5]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 38/8134 [00:05<17:13,  7.83it/s, Epoch=0, LR=0.001, Train_Loss=24.5]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 512])\n",
      "torch.Size([4, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 38/8134 [00:05<17:13,  7.83it/s, Epoch=0, LR=0.001, Train_Loss=24.5]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 39/8134 [00:05<17:38,  7.65it/s, Epoch=0, LR=0.001, Train_Loss=24.5]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 39/8134 [00:05<17:38,  7.65it/s, Epoch=0, LR=0.001, Train_Loss=24.4]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 40/8134 [00:05<17:21,  7.77it/s, Epoch=0, LR=0.001, Train_Loss=24.4]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 512])\n",
      "torch.Size([4, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 40/8134 [00:05<17:21,  7.77it/s, Epoch=0, LR=0.001, Train_Loss=24.5]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  1%|          | 41/8134 [00:05<17:04,  7.90it/s, Epoch=0, LR=0.001, Train_Loss=24.5]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  1%|          | 41/8134 [00:05<17:04,  7.90it/s, Epoch=0, LR=0.001, Train_Loss=24.5]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  1%|          | 42/8134 [00:05<17:48,  7.58it/s, Epoch=0, LR=0.001, Train_Loss=24.5]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 512])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-bacbf228ac4e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0muse_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muse_checkpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-75-fec3d1ffd575>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(use_checkpoint)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0mbest_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparallel_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mvalid_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparallel_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-71-780a0d8e1882>\u001b[0m in \u001b[0;36mtrain_fn\u001b[0;34m(dataloader, model, criterion, optimizer, device, scheduler, epoch)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc_device_obj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m                 raise RuntimeError(\"module must have its parameters and buffers \"\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mbuffers\u001b[0;34m(self, recurse)\u001b[0m\n\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m         \"\"\"\n\u001b[0;32m-> 1309\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_buffers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecurse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrecurse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1310\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mnamed_buffers\u001b[0;34m(self, prefix, recurse)\u001b[0m\n\u001b[1;32m   1333\u001b[0m             \u001b[0;32mlambda\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1334\u001b[0m             prefix=prefix, recurse=recurse)\n\u001b[0;32m-> 1335\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0melem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1336\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_named_members\u001b[0;34m(self, get_members_fn, prefix, recurse)\u001b[0m\n\u001b[1;32m   1229\u001b[0m         \u001b[0mmemo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1230\u001b[0m         \u001b[0mmodules\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_modules\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1231\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1232\u001b[0m             \u001b[0mmembers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_members_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1233\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmembers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mnamed_modules\u001b[0;34m(self, memo, prefix)\u001b[0m\n\u001b[1;32m   1427\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1428\u001b[0m                 \u001b[0msubmodule_prefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1429\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_modules\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmemo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubmodule_prefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1430\u001b[0m                     \u001b[0;32myield\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mnamed_modules\u001b[0;34m(self, memo, prefix)\u001b[0m\n\u001b[1;32m   1427\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1428\u001b[0m                 \u001b[0msubmodule_prefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1429\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_modules\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmemo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubmodule_prefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1430\u001b[0m                     \u001b[0;32myield\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mnamed_modules\u001b[0;34m(self, memo, prefix)\u001b[0m\n\u001b[1;32m   1427\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1428\u001b[0m                 \u001b[0msubmodule_prefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1429\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_modules\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmemo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubmodule_prefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1430\u001b[0m                     \u001b[0;32myield\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mnamed_modules\u001b[0;34m(self, memo, prefix)\u001b[0m\n\u001b[1;32m   1427\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1428\u001b[0m                 \u001b[0msubmodule_prefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1429\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_modules\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmemo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubmodule_prefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1430\u001b[0m                     \u001b[0;32myield\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mnamed_modules\u001b[0;34m(self, memo, prefix)\u001b[0m\n\u001b[1;32m   1427\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1428\u001b[0m                 \u001b[0msubmodule_prefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1429\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_modules\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmemo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubmodule_prefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1430\u001b[0m                     \u001b[0;32myield\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mnamed_modules\u001b[0;34m(self, memo, prefix)\u001b[0m\n\u001b[1;32m   1423\u001b[0m             \u001b[0mmemo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1424\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1425\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1426\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1427\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "use_checkpoint=False\n",
    "run(use_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patch_embed.proj.weight\n",
      "patch_embed.proj.bias\n",
      "patch_embed.norm.weight\n",
      "patch_embed.norm.bias\n",
      "layers.0.blocks.0.norm1.weight\n",
      "layers.0.blocks.0.norm1.bias\n",
      "layers.0.blocks.0.attn.relative_position_bias_table\n",
      "layers.0.blocks.0.attn.qkv.weight\n",
      "layers.0.blocks.0.attn.qkv.bias\n",
      "layers.0.blocks.0.attn.proj.weight\n",
      "layers.0.blocks.0.attn.proj.bias\n",
      "layers.0.blocks.0.norm2.weight\n",
      "layers.0.blocks.0.norm2.bias\n",
      "layers.0.blocks.0.mlp.fc1.weight\n",
      "layers.0.blocks.0.mlp.fc1.bias\n",
      "layers.0.blocks.0.mlp.fc2.weight\n",
      "layers.0.blocks.0.mlp.fc2.bias\n",
      "layers.0.blocks.1.norm1.weight\n",
      "layers.0.blocks.1.norm1.bias\n",
      "layers.0.blocks.1.attn.relative_position_bias_table\n",
      "layers.0.blocks.1.attn.qkv.weight\n",
      "layers.0.blocks.1.attn.qkv.bias\n",
      "layers.0.blocks.1.attn.proj.weight\n",
      "layers.0.blocks.1.attn.proj.bias\n",
      "layers.0.blocks.1.norm2.weight\n",
      "layers.0.blocks.1.norm2.bias\n",
      "layers.0.blocks.1.mlp.fc1.weight\n",
      "layers.0.blocks.1.mlp.fc1.bias\n",
      "layers.0.blocks.1.mlp.fc2.weight\n",
      "layers.0.blocks.1.mlp.fc2.bias\n",
      "layers.0.downsample.reduction.weight\n",
      "layers.0.downsample.norm.weight\n",
      "layers.0.downsample.norm.bias\n",
      "layers.1.blocks.0.norm1.weight\n",
      "layers.1.blocks.0.norm1.bias\n",
      "layers.1.blocks.0.attn.relative_position_bias_table\n",
      "layers.1.blocks.0.attn.qkv.weight\n",
      "layers.1.blocks.0.attn.qkv.bias\n",
      "layers.1.blocks.0.attn.proj.weight\n",
      "layers.1.blocks.0.attn.proj.bias\n",
      "layers.1.blocks.0.norm2.weight\n",
      "layers.1.blocks.0.norm2.bias\n",
      "layers.1.blocks.0.mlp.fc1.weight\n",
      "layers.1.blocks.0.mlp.fc1.bias\n",
      "layers.1.blocks.0.mlp.fc2.weight\n",
      "layers.1.blocks.0.mlp.fc2.bias\n",
      "layers.1.blocks.1.norm1.weight\n",
      "layers.1.blocks.1.norm1.bias\n",
      "layers.1.blocks.1.attn.relative_position_bias_table\n",
      "layers.1.blocks.1.attn.qkv.weight\n",
      "layers.1.blocks.1.attn.qkv.bias\n",
      "layers.1.blocks.1.attn.proj.weight\n",
      "layers.1.blocks.1.attn.proj.bias\n",
      "layers.1.blocks.1.norm2.weight\n",
      "layers.1.blocks.1.norm2.bias\n",
      "layers.1.blocks.1.mlp.fc1.weight\n",
      "layers.1.blocks.1.mlp.fc1.bias\n",
      "layers.1.blocks.1.mlp.fc2.weight\n",
      "layers.1.blocks.1.mlp.fc2.bias\n",
      "layers.1.downsample.reduction.weight\n",
      "layers.1.downsample.norm.weight\n",
      "layers.1.downsample.norm.bias\n",
      "layers.2.blocks.0.norm1.weight\n",
      "layers.2.blocks.0.norm1.bias\n",
      "layers.2.blocks.0.attn.relative_position_bias_table\n",
      "layers.2.blocks.0.attn.qkv.weight\n",
      "layers.2.blocks.0.attn.qkv.bias\n",
      "layers.2.blocks.0.attn.proj.weight\n",
      "layers.2.blocks.0.attn.proj.bias\n",
      "layers.2.blocks.0.norm2.weight\n",
      "layers.2.blocks.0.norm2.bias\n",
      "layers.2.blocks.0.mlp.fc1.weight\n",
      "layers.2.blocks.0.mlp.fc1.bias\n",
      "layers.2.blocks.0.mlp.fc2.weight\n",
      "layers.2.blocks.0.mlp.fc2.bias\n",
      "layers.2.blocks.1.norm1.weight\n",
      "layers.2.blocks.1.norm1.bias\n",
      "layers.2.blocks.1.attn.relative_position_bias_table\n",
      "layers.2.blocks.1.attn.qkv.weight\n",
      "layers.2.blocks.1.attn.qkv.bias\n",
      "layers.2.blocks.1.attn.proj.weight\n",
      "layers.2.blocks.1.attn.proj.bias\n",
      "layers.2.blocks.1.norm2.weight\n",
      "layers.2.blocks.1.norm2.bias\n",
      "layers.2.blocks.1.mlp.fc1.weight\n",
      "layers.2.blocks.1.mlp.fc1.bias\n",
      "layers.2.blocks.1.mlp.fc2.weight\n",
      "layers.2.blocks.1.mlp.fc2.bias\n",
      "layers.2.blocks.2.norm1.weight\n",
      "layers.2.blocks.2.norm1.bias\n",
      "layers.2.blocks.2.attn.relative_position_bias_table\n",
      "layers.2.blocks.2.attn.qkv.weight\n",
      "layers.2.blocks.2.attn.qkv.bias\n",
      "layers.2.blocks.2.attn.proj.weight\n",
      "layers.2.blocks.2.attn.proj.bias\n",
      "layers.2.blocks.2.norm2.weight\n",
      "layers.2.blocks.2.norm2.bias\n",
      "layers.2.blocks.2.mlp.fc1.weight\n",
      "layers.2.blocks.2.mlp.fc1.bias\n",
      "layers.2.blocks.2.mlp.fc2.weight\n",
      "layers.2.blocks.2.mlp.fc2.bias\n",
      "layers.2.blocks.3.norm1.weight\n",
      "layers.2.blocks.3.norm1.bias\n",
      "layers.2.blocks.3.attn.relative_position_bias_table\n",
      "layers.2.blocks.3.attn.qkv.weight\n",
      "layers.2.blocks.3.attn.qkv.bias\n",
      "layers.2.blocks.3.attn.proj.weight\n",
      "layers.2.blocks.3.attn.proj.bias\n",
      "layers.2.blocks.3.norm2.weight\n",
      "layers.2.blocks.3.norm2.bias\n",
      "layers.2.blocks.3.mlp.fc1.weight\n",
      "layers.2.blocks.3.mlp.fc1.bias\n",
      "layers.2.blocks.3.mlp.fc2.weight\n",
      "layers.2.blocks.3.mlp.fc2.bias\n",
      "layers.2.blocks.4.norm1.weight\n",
      "layers.2.blocks.4.norm1.bias\n",
      "layers.2.blocks.4.attn.relative_position_bias_table\n",
      "layers.2.blocks.4.attn.qkv.weight\n",
      "layers.2.blocks.4.attn.qkv.bias\n",
      "layers.2.blocks.4.attn.proj.weight\n",
      "layers.2.blocks.4.attn.proj.bias\n",
      "layers.2.blocks.4.norm2.weight\n",
      "layers.2.blocks.4.norm2.bias\n",
      "layers.2.blocks.4.mlp.fc1.weight\n",
      "layers.2.blocks.4.mlp.fc1.bias\n",
      "layers.2.blocks.4.mlp.fc2.weight\n",
      "layers.2.blocks.4.mlp.fc2.bias\n",
      "layers.2.blocks.5.norm1.weight\n",
      "layers.2.blocks.5.norm1.bias\n",
      "layers.2.blocks.5.attn.relative_position_bias_table\n",
      "layers.2.blocks.5.attn.qkv.weight\n",
      "layers.2.blocks.5.attn.qkv.bias\n",
      "layers.2.blocks.5.attn.proj.weight\n",
      "layers.2.blocks.5.attn.proj.bias\n",
      "layers.2.blocks.5.norm2.weight\n",
      "layers.2.blocks.5.norm2.bias\n",
      "layers.2.blocks.5.mlp.fc1.weight\n",
      "layers.2.blocks.5.mlp.fc1.bias\n",
      "layers.2.blocks.5.mlp.fc2.weight\n",
      "layers.2.blocks.5.mlp.fc2.bias\n",
      "layers.2.blocks.6.norm1.weight\n",
      "layers.2.blocks.6.norm1.bias\n",
      "layers.2.blocks.6.attn.relative_position_bias_table\n",
      "layers.2.blocks.6.attn.qkv.weight\n",
      "layers.2.blocks.6.attn.qkv.bias\n",
      "layers.2.blocks.6.attn.proj.weight\n",
      "layers.2.blocks.6.attn.proj.bias\n",
      "layers.2.blocks.6.norm2.weight\n",
      "layers.2.blocks.6.norm2.bias\n",
      "layers.2.blocks.6.mlp.fc1.weight\n",
      "layers.2.blocks.6.mlp.fc1.bias\n",
      "layers.2.blocks.6.mlp.fc2.weight\n",
      "layers.2.blocks.6.mlp.fc2.bias\n",
      "layers.2.blocks.7.norm1.weight\n",
      "layers.2.blocks.7.norm1.bias\n",
      "layers.2.blocks.7.attn.relative_position_bias_table\n",
      "layers.2.blocks.7.attn.qkv.weight\n",
      "layers.2.blocks.7.attn.qkv.bias\n",
      "layers.2.blocks.7.attn.proj.weight\n",
      "layers.2.blocks.7.attn.proj.bias\n",
      "layers.2.blocks.7.norm2.weight\n",
      "layers.2.blocks.7.norm2.bias\n",
      "layers.2.blocks.7.mlp.fc1.weight\n",
      "layers.2.blocks.7.mlp.fc1.bias\n",
      "layers.2.blocks.7.mlp.fc2.weight\n",
      "layers.2.blocks.7.mlp.fc2.bias\n",
      "layers.2.blocks.8.norm1.weight\n",
      "layers.2.blocks.8.norm1.bias\n",
      "layers.2.blocks.8.attn.relative_position_bias_table\n",
      "layers.2.blocks.8.attn.qkv.weight\n",
      "layers.2.blocks.8.attn.qkv.bias\n",
      "layers.2.blocks.8.attn.proj.weight\n",
      "layers.2.blocks.8.attn.proj.bias\n",
      "layers.2.blocks.8.norm2.weight\n",
      "layers.2.blocks.8.norm2.bias\n",
      "layers.2.blocks.8.mlp.fc1.weight\n",
      "layers.2.blocks.8.mlp.fc1.bias\n",
      "layers.2.blocks.8.mlp.fc2.weight\n",
      "layers.2.blocks.8.mlp.fc2.bias\n",
      "layers.2.blocks.9.norm1.weight\n",
      "layers.2.blocks.9.norm1.bias\n",
      "layers.2.blocks.9.attn.relative_position_bias_table\n",
      "layers.2.blocks.9.attn.qkv.weight\n",
      "layers.2.blocks.9.attn.qkv.bias\n",
      "layers.2.blocks.9.attn.proj.weight\n",
      "layers.2.blocks.9.attn.proj.bias\n",
      "layers.2.blocks.9.norm2.weight\n",
      "layers.2.blocks.9.norm2.bias\n",
      "layers.2.blocks.9.mlp.fc1.weight\n",
      "layers.2.blocks.9.mlp.fc1.bias\n",
      "layers.2.blocks.9.mlp.fc2.weight\n",
      "layers.2.blocks.9.mlp.fc2.bias\n",
      "layers.2.blocks.10.norm1.weight\n",
      "layers.2.blocks.10.norm1.bias\n",
      "layers.2.blocks.10.attn.relative_position_bias_table\n",
      "layers.2.blocks.10.attn.qkv.weight\n",
      "layers.2.blocks.10.attn.qkv.bias\n",
      "layers.2.blocks.10.attn.proj.weight\n",
      "layers.2.blocks.10.attn.proj.bias\n",
      "layers.2.blocks.10.norm2.weight\n",
      "layers.2.blocks.10.norm2.bias\n",
      "layers.2.blocks.10.mlp.fc1.weight\n",
      "layers.2.blocks.10.mlp.fc1.bias\n",
      "layers.2.blocks.10.mlp.fc2.weight\n",
      "layers.2.blocks.10.mlp.fc2.bias\n",
      "layers.2.blocks.11.norm1.weight\n",
      "layers.2.blocks.11.norm1.bias\n",
      "layers.2.blocks.11.attn.relative_position_bias_table\n",
      "layers.2.blocks.11.attn.qkv.weight\n",
      "layers.2.blocks.11.attn.qkv.bias\n",
      "layers.2.blocks.11.attn.proj.weight\n",
      "layers.2.blocks.11.attn.proj.bias\n",
      "layers.2.blocks.11.norm2.weight\n",
      "layers.2.blocks.11.norm2.bias\n",
      "layers.2.blocks.11.mlp.fc1.weight\n",
      "layers.2.blocks.11.mlp.fc1.bias\n",
      "layers.2.blocks.11.mlp.fc2.weight\n",
      "layers.2.blocks.11.mlp.fc2.bias\n",
      "layers.2.blocks.12.norm1.weight\n",
      "layers.2.blocks.12.norm1.bias\n",
      "layers.2.blocks.12.attn.relative_position_bias_table\n",
      "layers.2.blocks.12.attn.qkv.weight\n",
      "layers.2.blocks.12.attn.qkv.bias\n",
      "layers.2.blocks.12.attn.proj.weight\n",
      "layers.2.blocks.12.attn.proj.bias\n",
      "layers.2.blocks.12.norm2.weight\n",
      "layers.2.blocks.12.norm2.bias\n",
      "layers.2.blocks.12.mlp.fc1.weight\n",
      "layers.2.blocks.12.mlp.fc1.bias\n",
      "layers.2.blocks.12.mlp.fc2.weight\n",
      "layers.2.blocks.12.mlp.fc2.bias\n",
      "layers.2.blocks.13.norm1.weight\n",
      "layers.2.blocks.13.norm1.bias\n",
      "layers.2.blocks.13.attn.relative_position_bias_table\n",
      "layers.2.blocks.13.attn.qkv.weight\n",
      "layers.2.blocks.13.attn.qkv.bias\n",
      "layers.2.blocks.13.attn.proj.weight\n",
      "layers.2.blocks.13.attn.proj.bias\n",
      "layers.2.blocks.13.norm2.weight\n",
      "layers.2.blocks.13.norm2.bias\n",
      "layers.2.blocks.13.mlp.fc1.weight\n",
      "layers.2.blocks.13.mlp.fc1.bias\n",
      "layers.2.blocks.13.mlp.fc2.weight\n",
      "layers.2.blocks.13.mlp.fc2.bias\n",
      "layers.2.blocks.14.norm1.weight\n",
      "layers.2.blocks.14.norm1.bias\n",
      "layers.2.blocks.14.attn.relative_position_bias_table\n",
      "layers.2.blocks.14.attn.qkv.weight\n",
      "layers.2.blocks.14.attn.qkv.bias\n",
      "layers.2.blocks.14.attn.proj.weight\n",
      "layers.2.blocks.14.attn.proj.bias\n",
      "layers.2.blocks.14.norm2.weight\n",
      "layers.2.blocks.14.norm2.bias\n",
      "layers.2.blocks.14.mlp.fc1.weight\n",
      "layers.2.blocks.14.mlp.fc1.bias\n",
      "layers.2.blocks.14.mlp.fc2.weight\n",
      "layers.2.blocks.14.mlp.fc2.bias\n",
      "layers.2.blocks.15.norm1.weight\n",
      "layers.2.blocks.15.norm1.bias\n",
      "layers.2.blocks.15.attn.relative_position_bias_table\n",
      "layers.2.blocks.15.attn.qkv.weight\n",
      "layers.2.blocks.15.attn.qkv.bias\n",
      "layers.2.blocks.15.attn.proj.weight\n",
      "layers.2.blocks.15.attn.proj.bias\n",
      "layers.2.blocks.15.norm2.weight\n",
      "layers.2.blocks.15.norm2.bias\n",
      "layers.2.blocks.15.mlp.fc1.weight\n",
      "layers.2.blocks.15.mlp.fc1.bias\n",
      "layers.2.blocks.15.mlp.fc2.weight\n",
      "layers.2.blocks.15.mlp.fc2.bias\n",
      "layers.2.blocks.16.norm1.weight\n",
      "layers.2.blocks.16.norm1.bias\n",
      "layers.2.blocks.16.attn.relative_position_bias_table\n",
      "layers.2.blocks.16.attn.qkv.weight\n",
      "layers.2.blocks.16.attn.qkv.bias\n",
      "layers.2.blocks.16.attn.proj.weight\n",
      "layers.2.blocks.16.attn.proj.bias\n",
      "layers.2.blocks.16.norm2.weight\n",
      "layers.2.blocks.16.norm2.bias\n",
      "layers.2.blocks.16.mlp.fc1.weight\n",
      "layers.2.blocks.16.mlp.fc1.bias\n",
      "layers.2.blocks.16.mlp.fc2.weight\n",
      "layers.2.blocks.16.mlp.fc2.bias\n",
      "layers.2.blocks.17.norm1.weight\n",
      "layers.2.blocks.17.norm1.bias\n",
      "layers.2.blocks.17.attn.relative_position_bias_table\n",
      "layers.2.blocks.17.attn.qkv.weight\n",
      "layers.2.blocks.17.attn.qkv.bias\n",
      "layers.2.blocks.17.attn.proj.weight\n",
      "layers.2.blocks.17.attn.proj.bias\n",
      "layers.2.blocks.17.norm2.weight\n",
      "layers.2.blocks.17.norm2.bias\n",
      "layers.2.blocks.17.mlp.fc1.weight\n",
      "layers.2.blocks.17.mlp.fc1.bias\n",
      "layers.2.blocks.17.mlp.fc2.weight\n",
      "layers.2.blocks.17.mlp.fc2.bias\n",
      "layers.2.downsample.reduction.weight\n",
      "layers.2.downsample.norm.weight\n",
      "layers.2.downsample.norm.bias\n",
      "layers.3.blocks.0.norm1.weight\n",
      "layers.3.blocks.0.norm1.bias\n",
      "layers.3.blocks.0.attn.relative_position_bias_table\n",
      "layers.3.blocks.0.attn.qkv.weight\n",
      "layers.3.blocks.0.attn.qkv.bias\n",
      "layers.3.blocks.0.attn.proj.weight\n",
      "layers.3.blocks.0.attn.proj.bias\n",
      "layers.3.blocks.0.norm2.weight\n",
      "layers.3.blocks.0.norm2.bias\n",
      "layers.3.blocks.0.mlp.fc1.weight\n",
      "layers.3.blocks.0.mlp.fc1.bias\n",
      "layers.3.blocks.0.mlp.fc2.weight\n",
      "layers.3.blocks.0.mlp.fc2.bias\n",
      "layers.3.blocks.1.norm1.weight\n",
      "layers.3.blocks.1.norm1.bias\n",
      "layers.3.blocks.1.attn.relative_position_bias_table\n",
      "layers.3.blocks.1.attn.qkv.weight\n",
      "layers.3.blocks.1.attn.qkv.bias\n",
      "layers.3.blocks.1.attn.proj.weight\n",
      "layers.3.blocks.1.attn.proj.bias\n",
      "layers.3.blocks.1.norm2.weight\n",
      "layers.3.blocks.1.norm2.bias\n",
      "layers.3.blocks.1.mlp.fc1.weight\n",
      "layers.3.blocks.1.mlp.fc1.bias\n",
      "layers.3.blocks.1.mlp.fc2.weight\n",
      "layers.3.blocks.1.mlp.fc2.bias\n",
      "norm.weight\n",
      "norm.bias\n",
      "head.weight\n",
      "head.bias\n"
     ]
    }
   ],
   "source": [
    "# backbone = timm.create_model('swin_small_patch4_window7_224', pretrained=True)\n",
    "# for name, _ in backbone.named_parameters():\n",
    "#     print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(backbone.state_dict(),'SWIN.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = torch.nn.DataParallel(ShopeeNet(**model_params))\n",
    "# model.load_state_dict(torch.load('model_efficientnet_b4_IMG_SIZE_512_FullData.bin'))\n",
    "# model = model.to(device)\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.module.state_dict(),'model_efficientnet_b3_IMG_SIZE_512_FullData.bin') #!!!! IF use DataParallel"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
