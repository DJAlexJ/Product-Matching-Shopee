{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T17:46:15.088594Z",
     "iopub.status.busy": "2021-05-10T17:46:15.088066Z",
     "iopub.status.idle": "2021-05-10T17:46:15.092108Z",
     "shell.execute_reply": "2021-05-10T17:46:15.091505Z"
    },
    "papermill": {
     "duration": 0.030896,
     "end_time": "2021-05-10T17:46:15.092274",
     "exception": false,
     "start_time": "2021-05-10T17:46:15.061378",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../input/pytorch-image-models/pytorch-image-models-master')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T17:46:15.140466Z",
     "iopub.status.busy": "2021-05-10T17:46:15.139868Z",
     "iopub.status.idle": "2021-05-10T17:46:24.061027Z",
     "shell.execute_reply": "2021-05-10T17:46:24.060552Z"
    },
    "papermill": {
     "duration": 8.947808,
     "end_time": "2021-05-10T17:46:24.061160",
     "exception": false,
     "start_time": "2021-05-10T17:46:15.113352",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Preliminaries\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import random\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visuals and CV2\n",
    "import cv2\n",
    "import seaborn as sns\n",
    "\n",
    "# albumentations for augs\n",
    "import albumentations\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "\n",
    "#torch\n",
    "import torch\n",
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Parameter\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "\n",
    "\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import cudf\n",
    "import cuml\n",
    "import cupy\n",
    "from cuml.feature_extraction.text import TfidfVectorizer\n",
    "from cuml import PCA\n",
    "from cuml.neighbors import NearestNeighbors\n",
    "from cuml.metrics import pairwise_distances\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "import transformers\n",
    "import nltk\n",
    "\n",
    "import lightgbm as lgb\n",
    "import joblib\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T17:46:24.124194Z",
     "iopub.status.busy": "2021-05-10T17:46:24.122583Z",
     "iopub.status.idle": "2021-05-10T17:46:25.785164Z",
     "shell.execute_reply": "2021-05-10T17:46:25.785653Z"
    },
    "papermill": {
     "duration": 1.7032,
     "end_time": "2021-05-10T17:46:25.785834",
     "exception": false,
     "start_time": "2021-05-10T17:46:24.082634",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this submission notebook will compute CV score, but commit notebook will not\n"
     ]
    }
   ],
   "source": [
    "DIM768 = (768, 768)\n",
    "DIM544 = (544, 544)\n",
    "DIM512 = (512, 512)\n",
    "DIM224 = (224, 224)\n",
    "\n",
    "NUM_WORKERS = 4\n",
    "BATCH_SIZE = 12\n",
    "SEED = 2020\n",
    "\n",
    "device = torch.device('cuda')\n",
    "\n",
    "CLASSES = 11014\n",
    "\n",
    "FEATURES = ['effnet512_dist', 'nfnet512_dist', 'tfidf_dist', 'bert_dist', 'sentence_dist']\n",
    "TFIDF = ['tfidf_dist']\n",
    "tfidf_coef = 0.2\n",
    "CV = ['effnet512_dist', 'nfnet512_dist']\n",
    "cv_coef = 0.5\n",
    "TEXT = ['bert_dist', 'sentence_dist']\n",
    "text_coef = 0.3\n",
    "# FEATURES = ['effnet768_dist', 'effnet512_dist', 'effnet224_dist', 'nfnet512_dist', 'tfidf_dist', 'bert_dist']\n",
    "\n",
    "KNN_classifier = 100\n",
    "\n",
    "################################################  ADJUSTING FOR CV OR SUBMIT ##############################################\n",
    "\n",
    "CHECK_SUB = False\n",
    "GET_CV = True\n",
    "SHORT = False\n",
    "\n",
    "test = pd.read_csv('../input/shopee-product-matching/test.csv')\n",
    "if len(test)>3: GET_CV = False\n",
    "else: print('this submission notebook will compute CV score, but commit notebook will not')\n",
    "\n",
    "\n",
    "################################################# MODEL ####################################################################\n",
    "\n",
    "# model_name = 'efficientnet_b3' #efficientnet_b0-b7\n",
    "\n",
    "################################################ MODEL PATH ###############################################################\n",
    "\n",
    "PATH_EFFNET_224 = '../input/shopee-models/model_efficientnet_b3_IMG_SIZE_224_arcface_9.088_FullData.bin'\n",
    "PATH_EFFNET_512 = '../input/shopee-models/model_efficientnet_b4_IMG_SIZE_512_arcface_8.395_FullData.bin'\n",
    "PATH_EFFNET_768 = '../input/shopee-models/model_efficientnet_b3_IMG_SIZE_768_arcface_9.358_FullData.bin'\n",
    "PATH_NFNET_512 = '../input/shopee-models/model_eca_nfnet_l0_IMG_SIZE_512_arcface_8.239_FullData.bin'\n",
    "PATH_XCEPT_512 = '../input/shopee-models/XCEPTION_512_arcface_9.596_RMAC_GEM.bin'\n",
    "PATH_NFNET_TEMP_512 = '../input/shopee-models/model_eca_nfnet_l0_IMG_SIZE_512_arcface_6.501_FullData_temp_2.bin'\n",
    "\n",
    "\n",
    "PATH_DISTIL_BERT = '../input/shopee-models/DistilBertFullData.pt'\n",
    "PATH_IND_ROBERTA = '../input/shopee-text-indonesian-roberta/indonesian_roberta_base_best_loss_num_epochs_60_arcface.bin'\n",
    "PATH_SENTENCE_MODEL = '../input/shopee-text-sentence-transformers-multilingual/sentence_transfomer_bert_best_loss_num_epochs_70_arcface.bin'\n",
    "\n",
    "################################################ Metric Loss and its params #######################################################\n",
    "loss_module = 'arcface' #'cosface' #'adacos'\n",
    "s = 30.0\n",
    "m = 0.5 \n",
    "ls_eps = 0.0\n",
    "easy_margin = False\n",
    "\n",
    "model_params = {\n",
    "    'n_classes':11014,\n",
    "    'use_fc':True,\n",
    "    'temperature': 0,\n",
    "    'fc_dim':512,\n",
    "    'dropout':0.0,\n",
    "    'loss_module':loss_module,\n",
    "    's':30.0,\n",
    "    'margin':0.50,\n",
    "    'ls_eps':0.0,\n",
    "    'theta_zero':0.785,\n",
    "    'pretrained':False\n",
    "}\n",
    "\n",
    "transformer_model = '../input/paraphrase-xlm-r-multilingual-v1/0_Transformer'\n",
    "TOKENIZER = transformers.AutoTokenizer.from_pretrained(transformer_model)\n",
    "\n",
    "sentence_params = {\n",
    "    'n_classes':11014,\n",
    "    'model_name':transformer_model,\n",
    "    'pooling':'mean_pooling',   #max_pooling , #mean_pooling\n",
    "    'use_fc':False,\n",
    "    'fc_dim':512,\n",
    "    'dropout':0.3,\n",
    "    'loss_module':loss_module,\n",
    "    's':30.0,\n",
    "    'margin':0.50,\n",
    "    'ls_eps':0.0,\n",
    "    'theta_zero':0.785\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T17:46:25.842772Z",
     "iopub.status.busy": "2021-05-10T17:46:25.841823Z",
     "iopub.status.idle": "2021-05-10T17:46:25.844726Z",
     "shell.execute_reply": "2021-05-10T17:46:25.844333Z"
    },
    "papermill": {
     "duration": 0.035302,
     "end_time": "2021-05-10T17:46:25.844838",
     "exception": false,
     "start_time": "2021-05-10T17:46:25.809536",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "to_eng = { \"wanita\": \"woman\", \"anak\": \"child\", \"bayi\": \"baby\", \"tas\": \"bag\", \"masker\": \"face mask\", \"pria\": \"men\", \"murah\": \"cheap\", \"tangan\": \"hand\", \"alat\": \"tool\", \"motif\": \"motive\", \"warna\": \"color\", \"bahan\": \"material\", \"celana\": \"pants\", \"baju\": \"clothes\", \"kaos\": \"t-shirt\", \"sepatu\": \"shoes\", \"rambut\": \"hair\", \"mainan\": \"toy\", \"sarung\": \"holster\", \"polos\": \"plain\", \"rak\": \"rack\", \"botol\": \"bottle\", \"sabun\": \"soap\", \"kain\": \"fabric\", \"panjang\": \"long\", \"kabel\": \"cable\", \"buku\": \"book\", \"plastik\": \"plastic\", \"mobil\": \"car\", \"hitam\": \"black\", \"karakter\": \"character\", \"putih\": \"white\", \"dompet\": \"purse\", \"kaki\": \"feet\", \"pembersih\": \"cleaners\", \"lipat\": \"folding\", \"silikon\": \"silicone\", \"minyak\": \"oil\", \"isi\": \"contents\", \"paket\": \"package\", \"susu\": \"milk\", \"gamis\": \"robe\", \"mandi\": \"bath\", \"madu\": \"honey\", \"kulit\": \"skin\", \"serbaguna\": \"multipurpose\", \"bisa\": \"can\", \"kacamata\": \"spectacles\", \"pendek\": \"short\", \"tali\": \"rope\", \"selempang\": \"sash\", \"topi\": \"hat\", \"obat\": \"drug\", \"gantungan\": \"hanger\", \"tahun\": \"year\", \"jilbab\": \"hijab\", \"dapur\": \"kitchen\", \"dinding\": \"wall\", \"kuas\": \"brush\", \"perempuan\": \"woman\", \"katun\": \"cotton\", \"sepeda\": \"bike\", \"lucu\": \"funny\", \"lengan\": \"arm\", \"kaca\": \"glass\", \"garansi\": \"warranty\", \"bunga\": \"flower\", \"handuk\": \"towel\", \"dewasa\": \"adult\", \"elektrik\": \"electric\", \"timbangan\": \"balance\", \"besar\": \"big\", \"bahan\": \"ingredient\", \"ransel\": \"backpack\", \"kertas\": \"paper\"}\n",
    "to_ind = {v: k for k, v in to_eng.items()}\n",
    "to_ind_reg = {r'(\\b){}(\\b)'.format(k):r'\\1{}\\2'.format(v) for k,v in to_ind.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T17:46:25.900610Z",
     "iopub.status.busy": "2021-05-10T17:46:25.899802Z",
     "iopub.status.idle": "2021-05-10T17:46:25.903760Z",
     "shell.execute_reply": "2021-05-10T17:46:25.903363Z"
    },
    "papermill": {
     "duration": 0.034939,
     "end_time": "2021-05-10T17:46:25.903869",
     "exception": false,
     "start_time": "2021-05-10T17:46:25.868930",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_dataset():\n",
    "    if GET_CV:\n",
    "#         df = pd.read_csv('../input/shopee-product-matching/train.csv')\n",
    "        df = pd.read_csv('../input/shopee-folds/train_fold.csv')\n",
    "        df = df[df.fold == 0]\n",
    "        if SHORT:\n",
    "            df = df.sample(150)\n",
    "        df['title'] = df.title.apply(lambda x: x.lower().replace('\\\\', ' '))\n",
    "        df['title'] = df['title'].replace(to_ind_reg, regex=True)\n",
    "        tmp = df.groupby(['label_group'])['posting_id'].unique().to_dict()\n",
    "        df['matches'] = df['label_group'].map(tmp)\n",
    "        df['matches'] = df['matches'].apply(lambda x: ' '.join(x))\n",
    "        if CHECK_SUB:\n",
    "            df = pd.concat([df, df], axis = 0)\n",
    "            df.reset_index(drop = True, inplace = True)\n",
    "        df_cu = cudf.DataFrame(df)\n",
    "        image_paths = '../input/shopee-product-matching/train_images/' + df['image']\n",
    "    else:\n",
    "        df = pd.read_csv('../input/shopee-product-matching/test.csv')\n",
    "        df['title'] = df.title.apply(lambda x: x.lower().replace('\\\\', ' '))\n",
    "        df['title'] = df['title'].replace(to_ind_reg, regex=True)\n",
    "        df_cu = cudf.DataFrame(df)\n",
    "        image_paths = '../input/shopee-product-matching/test_images/' + df['image']\n",
    "        \n",
    "    return df, df_cu, image_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T17:46:25.955460Z",
     "iopub.status.busy": "2021-05-10T17:46:25.954873Z",
     "iopub.status.idle": "2021-05-10T17:46:25.960340Z",
     "shell.execute_reply": "2021-05-10T17:46:25.959788Z"
    },
    "papermill": {
     "duration": 0.033125,
     "end_time": "2021-05-10T17:46:25.960451",
     "exception": false,
     "start_time": "2021-05-10T17:46:25.927326",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def seed_torch(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "seed_torch(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T17:46:26.010124Z",
     "iopub.status.busy": "2021-05-10T17:46:26.009305Z",
     "iopub.status.idle": "2021-05-10T17:46:26.034536Z",
     "shell.execute_reply": "2021-05-10T17:46:26.034062Z"
    },
    "papermill": {
     "duration": 0.051043,
     "end_time": "2021-05-10T17:46:26.034645",
     "exception": false,
     "start_time": "2021-05-10T17:46:25.983602",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def f1_score(y_true, y_pred):\n",
    "    y_true = y_true.apply(lambda x: set(x.split()))\n",
    "    y_pred = y_pred.apply(lambda x: set(x.split()))\n",
    "    intersection = np.array([len(x[0] & x[1]) for x in zip(y_true, y_pred)])\n",
    "    len_y_pred = y_pred.apply(lambda x: len(x)).values\n",
    "    len_y_true = y_true.apply(lambda x: len(x)).values\n",
    "    f1 = 2 * intersection / (len_y_pred + len_y_true)\n",
    "    return f1\n",
    "\n",
    "def prec_score(y_true, y_pred):\n",
    "    y_true = y_true.apply(lambda x: set(x.split()))\n",
    "    y_pred = y_pred.apply(lambda x: set(x.split()))\n",
    "    intersection = np.array([len(x[0] & x[1]) for x in zip(y_true, y_pred)])\n",
    "    len_y_pred = y_pred.apply(lambda x: len(x)).values\n",
    "    len_y_true = y_true.apply(lambda x: len(x)).values\n",
    "    precision = intersection / (len_y_pred)\n",
    "    return precision\n",
    "\n",
    "def recall_score(y_true, y_pred):\n",
    "    y_true = y_true.apply(lambda x: set(x.split()))\n",
    "    y_pred = y_pred.apply(lambda x: set(x.split()))\n",
    "    intersection = np.array([len(x[0] & x[1]) for x in zip(y_true, y_pred)])\n",
    "    len_y_pred = y_pred.apply(lambda x: len(x)).values\n",
    "    len_y_true = y_true.apply(lambda x: len(x)).values\n",
    "    recall = intersection / (len_y_true)\n",
    "    return recall\n",
    "\n",
    "\n",
    "def combine_predictions(row):\n",
    "    x = np.concatenate([row['image_predictions'], row['text_predictions'], row['bert_predictions']])\n",
    "    return ' '.join(np.unique(x))\n",
    "\n",
    "\n",
    "def get_neighbors(df, embeddings, KNN = 50, type_='image'):\n",
    "    model = NearestNeighbors(n_neighbors = KNN)\n",
    "    model.fit(embeddings)\n",
    "    distances, indices = model.kneighbors(embeddings)\n",
    "    \n",
    "    # Iterate through different thresholds to maximize cv, run this in interactive mode, then replace else clause with a solid threshold\n",
    "    if GET_CV:\n",
    "        if type_ == 'bert':\n",
    "            thresholds = list(np.arange(1, 35, 1))\n",
    "        else:\n",
    "            thresholds = list(np.arange(0.01, 1, 0.05))\n",
    "        scores = []\n",
    "        for threshold in thresholds:\n",
    "            predictions = []\n",
    "            for k in range(embeddings.shape[0]):\n",
    "                idx = np.where(distances[k,] < threshold)[0]\n",
    "                ids = indices[k,idx]\n",
    "                posting_ids = ' '.join(df['posting_id'].iloc[ids].values)\n",
    "                predictions.append(posting_ids)\n",
    "            df['pred_matches'] = predictions\n",
    "            df['f1'] = f1_score(df['matches'], df['pred_matches'])\n",
    "            df['precision'] = prec_score(df['matches'], df['pred_matches'])\n",
    "            df['recall'] = recall_score(df['matches'], df['pred_matches'])\n",
    "            score = df['f1'].mean()\n",
    "            print(f'Our f1 score for threshold {threshold} is {score}')\n",
    "            print(f\"Our precision score for threshold {threshold} is {df['precision'].mean()}\")\n",
    "            print(f\"Our recall score for threshold {threshold} is {df['recall'].mean()}\")\n",
    "            scores.append(score)\n",
    "        thresholds_scores = pd.DataFrame({'thresholds': thresholds, 'scores': scores})\n",
    "        max_score = thresholds_scores[thresholds_scores['scores'] == thresholds_scores['scores'].max()]\n",
    "        best_threshold = max_score['thresholds'].values[0]\n",
    "        best_score = max_score['scores'].values[0]\n",
    "        print(f'Our best score is {best_score} and has a threshold {best_threshold}')\n",
    "        \n",
    "        # Use threshold\n",
    "        predictions = []\n",
    "        for k in range(embeddings.shape[0]):\n",
    "            # Because we are predicting the test set that have 70K images and different label groups, confidence should be smaller\n",
    "            idx = np.where(distances[k,] < best_threshold)[0]\n",
    "            ids = indices[k,idx]\n",
    "            posting_ids = df['posting_id'].iloc[ids].values\n",
    "            predictions.append(posting_ids)\n",
    "    \n",
    "    # Because we are predicting the test set that have 70K images and different label groups, confidence should be smaller\n",
    "    else:\n",
    "        predictions = []\n",
    "        for k in tqdm(range(embeddings.shape[0])):\n",
    "            if type_=='image':\n",
    "                idx = np.where(distances[k,] < 0.65)[0]\n",
    "            elif type_=='bert':\n",
    "                idx = np.where(distances[k,] < 7.5)[0]\n",
    "            else:\n",
    "                idx = np.where(distances[k,] < 0.7)[0]\n",
    "            ids = indices[k,idx]\n",
    "            posting_ids = df['posting_id'].iloc[ids].values\n",
    "            predictions.append(posting_ids)\n",
    "        \n",
    "    del model, distances, indices\n",
    "    gc.collect()\n",
    "    return df, predictions\n",
    "\n",
    "def get_test_transforms(DIM):\n",
    "    return albumentations.Compose(\n",
    "        [\n",
    "            albumentations.Resize(DIM[0],DIM[1],always_apply=True),\n",
    "            albumentations.Normalize(),\n",
    "        ToTensorV2(p=1.0)\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T17:46:26.095194Z",
     "iopub.status.busy": "2021-05-10T17:46:26.094503Z",
     "iopub.status.idle": "2021-05-10T17:46:26.097750Z",
     "shell.execute_reply": "2021-05-10T17:46:26.097326Z"
    },
    "papermill": {
     "duration": 0.04029,
     "end_time": "2021-05-10T17:46:26.097853",
     "exception": false,
     "start_time": "2021-05-10T17:46:26.057563",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ShopeeDataset(Dataset):\n",
    "    def __init__(self, image_paths, transforms=None):\n",
    "\n",
    "        self.image_paths = image_paths\n",
    "        self.augmentations = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.image_paths.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_path = self.image_paths[index]\n",
    "        \n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        if self.augmentations:\n",
    "            augmented = self.augmentations(image=image)\n",
    "            image = augmented['image']       \n",
    "        \n",
    "        \n",
    "        return image,torch.tensor(1)\n",
    "    \n",
    "\n",
    "class TextDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, mode=\"train\", max_length=None):\n",
    "        self.dataframe = dataframe\n",
    "        if mode != \"test\":\n",
    "            self.targets = dataframe['label_code'].values\n",
    "        texts = list(dataframe['title'].apply(lambda o: str(o)).values)\n",
    "        self.encodings = tokenizer(texts, \n",
    "                                   padding=True, \n",
    "                                   truncation=True, \n",
    "                                   max_length=max_length)\n",
    "        self.mode = mode\n",
    "        \n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        # putting each tensor in front of the corresponding key from the tokenizer\n",
    "        # HuggingFace tokenizers give you whatever you need to feed to the corresponding model\n",
    "        item = {key: torch.tensor(values[idx]) for key, values in self.encodings.items()}\n",
    "        # when testing, there are no targets so we won't do the following\n",
    "        if self.mode != \"test\":\n",
    "            item['labels'] = torch.tensor(self.targets[idx]).long()\n",
    "        return item\n",
    "    \n",
    "class SentenceDataset(Dataset):\n",
    "    def __init__(self, csv):\n",
    "        self.csv = csv.reset_index()\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.csv.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.csv.iloc[index]\n",
    "        \n",
    "        text = row.title\n",
    "        \n",
    "        text = TOKENIZER(text, padding='max_length', truncation=True, max_length=64, return_tensors=\"pt\")\n",
    "        input_ids = text['input_ids'][0]\n",
    "        attention_mask = text['attention_mask'][0]  \n",
    "        \n",
    "        return input_ids, attention_mask, torch.tensor(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T17:46:26.175459Z",
     "iopub.status.busy": "2021-05-10T17:46:26.158605Z",
     "iopub.status.idle": "2021-05-10T17:46:33.918204Z",
     "shell.execute_reply": "2021-05-10T17:46:33.917586Z"
    },
    "papermill": {
     "duration": 7.7969,
     "end_time": "2021-05-10T17:46:33.918364",
     "exception": false,
     "start_time": "2021-05-10T17:46:26.121464",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    DistilBERT = True # if set to False, BERT model will be used\n",
    "    bert_hidden_size = 768\n",
    "    \n",
    "    batch_size = 128\n",
    "    epochs = 200\n",
    "    num_workers = 4\n",
    "    learning_rate = 3e-5 #3e-5\n",
    "    scheduler = \"ReduceLROnPlateau\"\n",
    "    step = 'epoch'\n",
    "    patience = 2\n",
    "    factor = 0.8\n",
    "    dropout = 0.5\n",
    "    model_path = \"./\"\n",
    "    max_length = 60\n",
    "    model_save_name = \"distil_bert.pt\"\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "if CFG.DistilBERT:\n",
    "    model_name='../input/distilbert-base-indonesian'\n",
    "    tokenizer = DistilBertTokenizer.from_pretrained(model_name)\n",
    "    bert_model = DistilBertModel.from_pretrained(model_name)\n",
    "    \n",
    "class BertModel(nn.Module):\n",
    "    def __init__(self, \n",
    "                 bert_model, \n",
    "                 num_classes=11014, \n",
    "                 last_hidden_size=CFG.bert_hidden_size):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.bert_model = bert_model\n",
    "        self.arc_margin = ArcMarginProduct(last_hidden_size, \n",
    "                                           num_classes, \n",
    "                                           s=30.0, \n",
    "                                           m=0.50, \n",
    "                                           easy_margin=False)\n",
    "    \n",
    "    def get_bert_features(self, batch):\n",
    "        output = self.bert_model(input_ids=batch['input_ids'], attention_mask=batch['attention_mask'])\n",
    "        last_hidden_state = output.last_hidden_state # shape: (batch_size, seq_length, bert_hidden_dim)\n",
    "        CLS_token_state = last_hidden_state[:, 0, :] # obtaining CLS token state which is the first token.\n",
    "        return CLS_token_state\n",
    "    \n",
    "    def forward(self, batch):\n",
    "        CLS_hidden_state = self.get_bert_features(batch)\n",
    "        #output = self.arc_margin(CLS_hidden_state, batch['labels'])\n",
    "        return CLS_hidden_state\n",
    "     \n",
    "\n",
    "        \n",
    "class SentenceModel(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                 n_classes,\n",
    "                 model_name='bert-base-uncased',\n",
    "                 pooling='mean_pooling',\n",
    "                 use_fc=False,\n",
    "                 fc_dim=512,\n",
    "                 dropout=0.0,\n",
    "                 loss_module='softmax',\n",
    "                 s=30.0,\n",
    "                 margin=0.50,\n",
    "                 ls_eps=0.0,\n",
    "                 theta_zero=0.785):\n",
    "        \"\"\"\n",
    "        :param n_classes:\n",
    "        :param model_name: name of model from pretrainedmodels\n",
    "            e.g. resnet50, resnext101_32x4d, pnasnet5large\n",
    "        :param pooling: One of ('SPoC', 'MAC', 'RMAC', 'GeM', 'Rpool', 'Flatten', 'CompactBilinearPooling')\n",
    "        :param loss_module: One of ('arcface', 'cosface', 'softmax')\n",
    "        \"\"\"\n",
    "        super(SentenceModel, self).__init__()\n",
    "\n",
    "        self.transformer = transformers.AutoModel.from_pretrained(transformer_model)\n",
    "        final_in_features = self.transformer.config.hidden_size\n",
    "        \n",
    "        self.pooling = pooling\n",
    "        self.use_fc = use_fc\n",
    "    \n",
    "        if use_fc:\n",
    "            self.dropout = nn.Dropout(p=dropout)\n",
    "            self.fc = nn.Linear(final_in_features, fc_dim)\n",
    "            self.bn = nn.BatchNorm1d(fc_dim)\n",
    "            self._init_params()\n",
    "            final_in_features = fc_dim\n",
    "\n",
    "        self.loss_module = loss_module\n",
    "        if loss_module == 'arcface':\n",
    "            self.final = ArcMarginProduct(final_in_features, n_classes,\n",
    "                                          s=s, m=margin, easy_margin=False, ls_eps=ls_eps)\n",
    "        else:\n",
    "            self.final = nn.Linear(final_in_features, n_classes)\n",
    "\n",
    "    def _init_params(self):\n",
    "        nn.init.xavier_normal_(self.fc.weight)\n",
    "        nn.init.constant_(self.fc.bias, 0)\n",
    "        nn.init.constant_(self.bn.weight, 1)\n",
    "        nn.init.constant_(self.bn.bias, 0)\n",
    "\n",
    "    def forward(self, input_ids,attention_mask, label):\n",
    "        feature = self.extract_feat(input_ids,attention_mask)\n",
    "        if self.loss_module == 'arcface':\n",
    "            logits = self.final(feature, label)\n",
    "        else:\n",
    "            logits = self.final(feature)\n",
    "        return feature, logits\n",
    "\n",
    "    def extract_feat(self, input_ids,attention_mask):\n",
    "        x = self.transformer(input_ids=input_ids,attention_mask=attention_mask)\n",
    "        \n",
    "        if self.pooling == 'mean_pooling':\n",
    "            features = x[0]\n",
    "            features = torch.mean(features,1)\n",
    "            #self.mean_pooling(x,attention_mask)\n",
    "        elif self.pooling == 'max_pooling':\n",
    "            festures = self.max_pooling(x,attention_mask)\n",
    "        else:\n",
    "            features = x[0]\n",
    "            features = features[:,0,:]\n",
    "\n",
    "        if self.use_fc:\n",
    "            features = self.dropout(features)\n",
    "            features = self.fc(features)\n",
    "            features = self.bn(features)\n",
    "\n",
    "        return features\n",
    "    \n",
    "    def max_pooling(self,model_output, attention_mask):\n",
    "        token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "        token_embeddings[input_mask_expanded == 0] = -1e9  # Set padding tokens to large negative value\n",
    "        max_over_time = torch.max(token_embeddings, 1)[0]\n",
    "        return max_over_time\n",
    "    \n",
    "    def mean_pooling(self,model_output, attention_mask):\n",
    "        token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "        sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n",
    "        sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "        return sum_embeddings / sum_mask\n",
    "    \n",
    "    \n",
    "class ShopeeNet(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                 n_classes,\n",
    "                 model_name='efficientnet_b0',\n",
    "                 use_fc=False,\n",
    "                 temperature=0,\n",
    "                 fc_dim=512,\n",
    "                 dropout=0.0,\n",
    "                 loss_module='softmax',\n",
    "                 s=30.0,\n",
    "                 margin=0.50,\n",
    "                 ls_eps=0.0,\n",
    "                 theta_zero=0.785,\n",
    "                 pretrained=False):\n",
    "        \"\"\"\n",
    "        :param n_classes:\n",
    "        :param model_name: name of model from pretrainedmodels\n",
    "            e.g. resnet50, resnext101_32x4d, pnasnet5large\n",
    "        :param pooling: One of ('SPoC', 'MAC', 'RMAC', 'GeM', 'Rpool', 'Flatten', 'CompactBilinearPooling')\n",
    "        :param loss_module: One of ('arcface', 'cosface', 'softmax')\n",
    "        \"\"\"\n",
    "        super(ShopeeNet, self).__init__()\n",
    "        print('Model building for {} backbone'.format(model_name))\n",
    "        \n",
    "        if temperature != 0:\n",
    "            self.temperature = nn.Parameter(torch.ones(1) * temperature)\n",
    "\n",
    "        self.backbone = timm.create_model(model_name, pretrained=pretrained)\n",
    "        if model_name.startswith('xception'):\n",
    "            final_in_features = self.backbone.fc.in_features\n",
    "            self.backbone.fc = nn.Identity()\n",
    "        if model_name.startswith('efficientnet'):\n",
    "            print(\"EFFNET\")\n",
    "            final_in_features = self.backbone.classifier.in_features\n",
    "            self.backbone.classifier = nn.Identity()\n",
    "        elif model_name.startswith('inception_resnet'):\n",
    "            print(\"INCEPTIONRESNET\")\n",
    "            final_in_features = self.backbone.classif.in_features\n",
    "            self.backbone.classif = nn.Identity()\n",
    "        elif 'nfnet' in model_name:\n",
    "            print(\"NFNET\")\n",
    "            final_in_features = self.backbone.head.fc.in_features\n",
    "            self.backbone.head = nn.Identity()\n",
    "            \n",
    "        self.backbone.global_pool = nn.Identity()\n",
    "        \n",
    "        if model_name.startswith('xception'):\n",
    "            self.rmac_pooling = RMAC()\n",
    "            self.gem_pooling = GeM()\n",
    "        \n",
    "        self.pooling =  nn.AdaptiveAvgPool2d(1)\n",
    "            \n",
    "        self.use_fc = use_fc\n",
    "        if use_fc:\n",
    "            self.dropout = nn.Dropout(p=dropout)\n",
    "            if model_name.startswith('xception'):\n",
    "                self.fc = nn.Linear(2*final_in_features, fc_dim)\n",
    "            else:\n",
    "                self.fc = nn.Linear(final_in_features, fc_dim)\n",
    "            self.bn1 = nn.BatchNorm2d(final_in_features)\n",
    "            self.bn2 = nn.BatchNorm1d(fc_dim)\n",
    "            self._init_params()\n",
    "            final_in_features = fc_dim\n",
    "\n",
    "        self.loss_module = loss_module\n",
    "        if loss_module == 'arcface':\n",
    "            self.final = ArcMarginProduct(final_in_features, n_classes,\n",
    "                                          s=s, m=margin, easy_margin=False, ls_eps=ls_eps)\n",
    "        elif loss_module == 'cosface':\n",
    "            self.final = AddMarginProduct(final_in_features, n_classes, s=s, m=margin)\n",
    "        elif loss_module == 'adacos':\n",
    "            self.final = AdaCos(final_in_features, n_classes, m=margin, theta_zero=theta_zero)\n",
    "        else:\n",
    "            self.final = nn.Linear(final_in_features, n_classes)\n",
    "\n",
    "    def _init_params(self):\n",
    "        nn.init.xavier_normal_(self.fc.weight)\n",
    "        nn.init.constant_(self.fc.bias, 0)\n",
    "        nn.init.constant_(self.bn1.weight, 1)\n",
    "        nn.init.constant_(self.bn1.bias, 0)\n",
    "        nn.init.constant_(self.bn2.weight, 1)\n",
    "        nn.init.constant_(self.bn2.bias, 0)\n",
    "\n",
    "    def forward(self, x, label):\n",
    "        feature = self.extract_feat(x)\n",
    "        if self.loss_module in ('arcface', 'cosface', 'adacos'):\n",
    "            logits = self.final(feature, label)\n",
    "        else:\n",
    "            logits = self.final(feature)\n",
    "        return feature, logits\n",
    "\n",
    "    def extract_feat(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        x = self.backbone(x)\n",
    "        x = self.bn1(x)\n",
    "    \n",
    "        try:\n",
    "            gem_x = self.gem_pooling(x).view(batch_size, -1)\n",
    "            rmac_x = self.rmac_pooling(x).view(batch_size, -1)\n",
    "            x = torch.cat([rmac_x, gem_x], axis=1)\n",
    "        except:\n",
    "            x = self.pooling(x).view(batch_size, -1)\n",
    "\n",
    "        if self.use_fc:\n",
    "            x = self.dropout(x)\n",
    "            x = self.fc(x)\n",
    "            x = self.bn2(x)\n",
    "            x = F.normalize(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T17:46:33.995598Z",
     "iopub.status.busy": "2021-05-10T17:46:33.988997Z",
     "iopub.status.idle": "2021-05-10T17:46:33.997988Z",
     "shell.execute_reply": "2021-05-10T17:46:33.998419Z"
    },
    "papermill": {
     "duration": 0.056176,
     "end_time": "2021-05-10T17:46:33.998564",
     "exception": false,
     "start_time": "2021-05-10T17:46:33.942388",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rmac(x, L=3, eps=1e-6):\n",
    "    ovr = 0.4 # desired overlap of neighboring regions\n",
    "    steps = torch.Tensor([2, 3, 4, 5, 6, 7]) # possible regions for the long dimension\n",
    "\n",
    "    W = x.size(3)\n",
    "    H = x.size(2)\n",
    "\n",
    "    w = min(W, H)\n",
    "    w2 = math.floor(w/2.0 - 1)\n",
    "\n",
    "    b = (max(H, W)-w)/(steps-1)\n",
    "    (tmp, idx) = torch.min(torch.abs(((w**2 - w*b)/w**2)-ovr), 0) # steps(idx) regions for long dimension\n",
    "\n",
    "    # region overplus per dimension\n",
    "    Wd = 0;\n",
    "    Hd = 0;\n",
    "    if H < W:  \n",
    "        Wd = idx.item() + 1\n",
    "    elif H > W:\n",
    "        Hd = idx.item() + 1\n",
    "\n",
    "    v = F.max_pool2d(x, (x.size(-2), x.size(-1)))\n",
    "    v = v / (torch.norm(v, p=2, dim=1, keepdim=True) + eps).expand_as(v)\n",
    "\n",
    "    for l in range(1, L+1):\n",
    "        wl = math.floor(2*w/(l+1))\n",
    "        wl2 = math.floor(wl/2 - 1)\n",
    "\n",
    "        if l+Wd == 1:\n",
    "            b = 0\n",
    "        else:\n",
    "            b = (W-wl)/(l+Wd-1)\n",
    "        cenW = torch.floor(wl2 + torch.Tensor(range(l-1+Wd+1))*b) - wl2 # center coordinates\n",
    "        if l+Hd == 1:\n",
    "            b = 0\n",
    "        else:\n",
    "            b = (H-wl)/(l+Hd-1)\n",
    "        cenH = torch.floor(wl2 + torch.Tensor(range(l-1+Hd+1))*b) - wl2 # center coordinates\n",
    "            \n",
    "        for i_ in cenH.tolist():\n",
    "            for j_ in cenW.tolist():\n",
    "                if wl == 0:\n",
    "                    continue\n",
    "                R = x[:,:,(int(i_)+torch.Tensor(range(wl)).long()).tolist(),:]\n",
    "                R = R[:,:,:,(int(j_)+torch.Tensor(range(wl)).long()).tolist()]\n",
    "                vt = F.max_pool2d(R, (R.size(-2), R.size(-1)))\n",
    "                vt = vt / (torch.norm(vt, p=2, dim=1, keepdim=True) + eps).expand_as(vt)\n",
    "                v += vt\n",
    "\n",
    "    return v\n",
    "\n",
    "\n",
    "def gem(x, p=3, eps=1e-6):\n",
    "    return F.avg_pool2d(x.clamp(min=eps).pow(p), (x.size(-2), x.size(-1))).pow(1./p)\n",
    "    # return F.lp_pool2d(F.threshold(x, eps, eps), p, (x.size(-2), x.size(-1))) # alternative\n",
    "\n",
    "\n",
    "    \n",
    "class RMAC(nn.Module):\n",
    "\n",
    "    def __init__(self, L=3, eps=1e-6):\n",
    "        super(RMAC,self).__init__()\n",
    "        self.L = L\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        return rmac(x, L=self.L, eps=self.eps)\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(' + 'L=' + '{}'.format(self.L) + ')'\n",
    "    \n",
    "    \n",
    "class GeM(nn.Module):\n",
    "\n",
    "    def __init__(self, p=4, eps=1e-6):\n",
    "        super(GeM,self).__init__()\n",
    "        self.p = Parameter(torch.ones(1)*p)\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        return gem(x, p=self.p, eps=self.eps)\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(' + 'p=' + '{:.4f}'.format(self.p.data.tolist()[0]) + ', ' + 'eps=' + str(self.eps) + ')'\n",
    "    \n",
    "class ArcMarginProduct(nn.Module):\n",
    "    r\"\"\"Implement of large margin arc distance: :\n",
    "        Args:\n",
    "            in_features: size of each input sample\n",
    "            out_features: size of each output sample\n",
    "            s: norm of input feature\n",
    "            m: margin\n",
    "            cos(theta + m)\n",
    "        \"\"\"\n",
    "    def __init__(self, in_features, out_features, s=30.0, m=0.50, easy_margin=False, ls_eps=0.0):\n",
    "        super(ArcMarginProduct, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.s = s\n",
    "        self.m = m\n",
    "        self.ls_eps = ls_eps  # label smoothing\n",
    "        self.weight = Parameter(torch.FloatTensor(out_features, in_features))\n",
    "        nn.init.xavier_uniform_(self.weight)\n",
    "\n",
    "        self.easy_margin = easy_margin\n",
    "        self.cos_m = math.cos(m)\n",
    "        self.sin_m = math.sin(m)\n",
    "        self.th = math.cos(math.pi - m)\n",
    "        self.mm = math.sin(math.pi - m) * m\n",
    "\n",
    "    def forward(self, input, label):\n",
    "        # --------------------------- cos(theta) & phi(theta) ---------------------------\n",
    "        cosine = F.linear(F.normalize(input), F.normalize(self.weight))\n",
    "        sine = torch.sqrt(1.0 - torch.pow(cosine, 2))\n",
    "        phi = cosine * self.cos_m - sine * self.sin_m\n",
    "        if self.easy_margin:\n",
    "            phi = torch.where(cosine > 0, phi, cosine)\n",
    "        else:\n",
    "            phi = torch.where(cosine > self.th, phi, cosine - self.mm)\n",
    "        # --------------------------- convert label to one-hot ---------------------------\n",
    "        # one_hot = torch.zeros(cosine.size(), requires_grad=True, device='cuda')\n",
    "        one_hot = torch.zeros(cosine.size(), device='cuda')\n",
    "        one_hot.scatter_(1, label.view(-1, 1).long(), 1)\n",
    "        if self.ls_eps > 0:\n",
    "            one_hot = (1 - self.ls_eps) * one_hot + self.ls_eps / self.out_features\n",
    "        # -------------torch.where(out_i = {x_i if condition_i else y_i) -------------\n",
    "        output = (one_hot * phi) + ((1.0 - one_hot) * cosine)\n",
    "        output *= self.s\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T17:46:34.064086Z",
     "iopub.status.busy": "2021-05-10T17:46:34.062089Z",
     "iopub.status.idle": "2021-05-10T17:46:34.064653Z",
     "shell.execute_reply": "2021-05-10T17:46:34.065053Z"
    },
    "papermill": {
     "duration": 0.043319,
     "end_time": "2021-05-10T17:46:34.065327",
     "exception": false,
     "start_time": "2021-05-10T17:46:34.022008",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_image_embeddings(image_paths, model_name, PATH_EFFNET, DIM):\n",
    "    embeds = []\n",
    "    \n",
    "    model = ShopeeNet(model_name=model_name, **model_params)\n",
    "    model.load_state_dict(torch.load(PATH_EFFNET))\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    image_dataset = ShopeeDataset(image_paths=image_paths,transforms=get_test_transforms(DIM))\n",
    "    image_loader = torch.utils.data.DataLoader(\n",
    "        image_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        pin_memory=True,\n",
    "        drop_last=False,\n",
    "        num_workers=NUM_WORKERS\n",
    "    )\n",
    "    \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for img,label in tqdm(image_loader): \n",
    "            img = img.cuda()\n",
    "            label = label.cuda()\n",
    "            feat, _ = model(img,label)\n",
    "            image_embeddings = feat.detach().cpu().numpy()\n",
    "            embeds.append(image_embeddings)\n",
    "    \n",
    "    \n",
    "    del model\n",
    "    image_embeddings = np.concatenate(embeds)\n",
    "    print(f'Our image embeddings shape is {image_embeddings.shape}')\n",
    "    del embeds\n",
    "    gc.collect()\n",
    "    return image_embeddings\n",
    "\n",
    "def get_bert_embeddings(df):\n",
    "    embeds = []\n",
    "    \n",
    "    bert_dataset = TextDataset(df, tokenizer, max_length=CFG.max_length, mode='test')\n",
    "    model = BertModel(bert_model).to(CFG.device)\n",
    "    model.load_state_dict(torch.load(PATH_DISTIL_BERT))\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    loader = torch.utils.data.DataLoader(\n",
    "        bert_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        pin_memory=True,\n",
    "        drop_last=False,\n",
    "        num_workers=NUM_WORKERS\n",
    "    )\n",
    "    \n",
    "    tqdm_object = tqdm(loader, total=len(loader))\n",
    "    for batch in tqdm_object:\n",
    "        batch = {k: v.to(CFG.device) for k, v in batch.items()}\n",
    "        preds = model(batch)\n",
    "        bert_embeddings = preds.detach().cpu().numpy()\n",
    "        embeds.append(bert_embeddings)\n",
    "    \n",
    "    del model\n",
    "    bert_embeddings = np.concatenate(embeds)\n",
    "    print(f'Our image embeddings shape is {bert_embeddings.shape}')\n",
    "    del embeds\n",
    "    gc.collect()\n",
    "    return bert_embeddings\n",
    "\n",
    "\n",
    "def get_sentence_embeddings(df):\n",
    "    embeds = []\n",
    "    \n",
    "    bert_dataset = SentenceDataset(csv=df)\n",
    "    model = SentenceModel(**sentence_params)\n",
    "    model.load_state_dict(torch.load(PATH_SENTENCE_MODEL))\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    loader = torch.utils.data.DataLoader(\n",
    "        bert_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        pin_memory=True,\n",
    "        drop_last=False,\n",
    "        num_workers=NUM_WORKERS\n",
    "    )\n",
    "    \n",
    "    tqdm_object = tqdm(enumerate(loader), total=len(loader))\n",
    "    for bi,d in tqdm_object:\n",
    "        \n",
    "        batch_size = d[0].shape[0]\n",
    "\n",
    "        input_ids = d[0]\n",
    "        attention_mask = d[1]\n",
    "        targets = d[2]\n",
    "\n",
    "        input_ids = input_ids.to(device)\n",
    "        attention_mask = attention_mask.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        preds, _ = model(input_ids,attention_mask,targets)\n",
    "        sentence_embeddings = preds.detach().cpu().numpy()\n",
    "        embeds.append(sentence_embeddings)\n",
    "        \n",
    "    \n",
    "    del model\n",
    "    sentence_embeddings = np.concatenate(embeds)\n",
    "    print(f'Our image embeddings shape is {sentence_embeddings.shape}')\n",
    "    del embeds\n",
    "    gc.collect()\n",
    "    return sentence_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T17:46:34.119600Z",
     "iopub.status.busy": "2021-05-10T17:46:34.117849Z",
     "iopub.status.idle": "2021-05-10T17:46:34.120179Z",
     "shell.execute_reply": "2021-05-10T17:46:34.120568Z"
    },
    "papermill": {
     "duration": 0.033013,
     "end_time": "2021-05-10T17:46:34.120693",
     "exception": false,
     "start_time": "2021-05-10T17:46:34.087680",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_text_embeddings(df_cu, max_features = 15000, n_components = 5000):\n",
    "    model = TfidfVectorizer(stop_words = 'english', binary = True, max_features = max_features)\n",
    "    text_embeddings = model.fit_transform(df_cu['title']).toarray()\n",
    "#     pca = PCA(n_components = n_components)\n",
    "#     text_embeddings = pca.fit_transform(text_embeddings).get()\n",
    "    print(f'Our title text embedding shape is {text_embeddings.shape}')\n",
    "#     del model, pca\n",
    "    del model\n",
    "    gc.collect()\n",
    "    return text_embeddings.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T17:46:34.175562Z",
     "iopub.status.busy": "2021-05-10T17:46:34.175055Z",
     "iopub.status.idle": "2021-05-10T17:46:44.358262Z",
     "shell.execute_reply": "2021-05-10T17:46:44.357769Z"
    },
    "papermill": {
     "duration": 10.215735,
     "end_time": "2021-05-10T17:46:44.358394",
     "exception": false,
     "start_time": "2021-05-10T17:46:34.142659",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>posting_id</th>\n",
       "      <th>image</th>\n",
       "      <th>image_phash</th>\n",
       "      <th>title</th>\n",
       "      <th>label_group</th>\n",
       "      <th>fold</th>\n",
       "      <th>matches</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>train_1806152124</td>\n",
       "      <td>0014f61389cbaa687a58e38a97b6383d.jpg</td>\n",
       "      <td>eea7e1c0c04da33d</td>\n",
       "      <td>kulot plisket salur /candy plisket /wish kulot...</td>\n",
       "      <td>1565741687</td>\n",
       "      <td>0</td>\n",
       "      <td>train_1806152124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>train_831680791</td>\n",
       "      <td>001be52b2beec40ddc1d2d7fc7a68f08.jpg</td>\n",
       "      <td>e1ce953d1a70618f</td>\n",
       "      <td>besar sale sepatu pantofel kulit keren kerja k...</td>\n",
       "      <td>2630990665</td>\n",
       "      <td>0</td>\n",
       "      <td>train_831680791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>train_4287573913</td>\n",
       "      <td>001f5580b058c6b8e33132190a757318.jpg</td>\n",
       "      <td>dc85e1750687f932</td>\n",
       "      <td>charger vizz vz-tc11 / batok charger vizz 1a o...</td>\n",
       "      <td>1932232224</td>\n",
       "      <td>0</td>\n",
       "      <td>train_4287573913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>train_2961381387</td>\n",
       "      <td>00303ad1c062fdeaf5f41b9ffb71a5fb.jpg</td>\n",
       "      <td>e48d9b652098efe1</td>\n",
       "      <td>madame gie makeup blush on by gisell</td>\n",
       "      <td>2098400894</td>\n",
       "      <td>0</td>\n",
       "      <td>train_2961381387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>train_2238403912</td>\n",
       "      <td>003524b70715bf6bfa00451ca08e66e0.jpg</td>\n",
       "      <td>ba35c44a3fb7c068</td>\n",
       "      <td>kangaroo teflon / allu fry pan 18 cm - kg652</td>\n",
       "      <td>531768918</td>\n",
       "      <td>0</td>\n",
       "      <td>train_2238403912</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          posting_id                                 image       image_phash  \\\n",
       "7   train_1806152124  0014f61389cbaa687a58e38a97b6383d.jpg  eea7e1c0c04da33d   \n",
       "9    train_831680791  001be52b2beec40ddc1d2d7fc7a68f08.jpg  e1ce953d1a70618f   \n",
       "14  train_4287573913  001f5580b058c6b8e33132190a757318.jpg  dc85e1750687f932   \n",
       "19  train_2961381387  00303ad1c062fdeaf5f41b9ffb71a5fb.jpg  e48d9b652098efe1   \n",
       "21  train_2238403912  003524b70715bf6bfa00451ca08e66e0.jpg  ba35c44a3fb7c068   \n",
       "\n",
       "                                                title  label_group  fold  \\\n",
       "7   kulot plisket salur /candy plisket /wish kulot...   1565741687     0   \n",
       "9   besar sale sepatu pantofel kulit keren kerja k...   2630990665     0   \n",
       "14  charger vizz vz-tc11 / batok charger vizz 1a o...   1932232224     0   \n",
       "19               madame gie makeup blush on by gisell   2098400894     0   \n",
       "21       kangaroo teflon / allu fry pan 18 cm - kg652    531768918     0   \n",
       "\n",
       "             matches  \n",
       "7   train_1806152124  \n",
       "9    train_831680791  \n",
       "14  train_4287573913  \n",
       "19  train_2961381387  \n",
       "21  train_2238403912  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df,df_cu,image_paths = read_dataset()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T17:46:44.473529Z",
     "iopub.status.busy": "2021-05-10T17:46:44.472841Z",
     "iopub.status.idle": "2021-05-10T17:46:44.476537Z",
     "shell.execute_reply": "2021-05-10T17:46:44.476083Z"
    },
    "papermill": {
     "duration": 0.034895,
     "end_time": "2021-05-10T17:46:44.476668",
     "exception": false,
     "start_time": "2021-05-10T17:46:44.441773",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_neighbors(embeddings, n):\n",
    "    if len(df) > 3:\n",
    "        n = n\n",
    "    else: \n",
    "        n = 3\n",
    "    weights = np.logspace(0, -1.5, n)\n",
    "    model = NearestNeighbors(n_neighbors=n, metric='cosine')\n",
    "    model.fit(embeddings)\n",
    "    distances, indices = model.kneighbors(embeddings)\n",
    "    \n",
    "    neighbors = []\n",
    "    for k in range(embeddings.shape[0]):\n",
    "        emb = (embeddings[indices[k, ]])\n",
    "        nearers = np.dot(weights, emb)\n",
    "        neighbors.append(nearers)\n",
    "        \n",
    "    neighbors = np.vstack(neighbors)\n",
    "    \n",
    "    del model, distances, indices\n",
    "    gc.collect()\n",
    "    return neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T17:46:44.558533Z",
     "iopub.status.busy": "2021-05-10T17:46:44.548404Z",
     "iopub.status.idle": "2021-05-10T17:52:36.608613Z",
     "shell.execute_reply": "2021-05-10T17:52:36.608123Z"
    },
    "papermill": {
     "duration": 352.107301,
     "end_time": "2021-05-10T17:52:36.608770",
     "exception": false,
     "start_time": "2021-05-10T17:46:44.501469",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 571/571 [00:09<00:00, 58.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our image embeddings shape is (6850, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 571/571 [00:17<00:00, 32.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our image embeddings shape is (6850, 768)\n",
      "Model building for efficientnet_b3 backbone\n",
      "EFFNET\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 571/571 [02:10<00:00,  4.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our image embeddings shape is (6850, 512)\n",
      "Model building for eca_nfnet_l0 backbone\n",
      "NFNET\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 571/571 [02:13<00:00,  4.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our image embeddings shape is (6850, 512)\n",
      "Our title text embedding shape is (6850, 12185)\n"
     ]
    }
   ],
   "source": [
    "bert_embeddings = get_bert_embeddings(df)\n",
    "sentence_embeddings = get_sentence_embeddings(df)\n",
    "\n",
    "image512_embeddings = get_image_embeddings(image_paths.values, 'efficientnet_b3', PATH_EFFNET_512, DIM544)\n",
    "image512_embeddings_nfnet = get_image_embeddings(image_paths.values, 'eca_nfnet_l0', PATH_NFNET_512, DIM544)\n",
    "\n",
    "text_embeddings = get_text_embeddings(df_cu, max_features = 15000, n_components = 5000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T17:52:37.432657Z",
     "iopub.status.busy": "2021-05-10T17:52:37.431726Z",
     "iopub.status.idle": "2021-05-10T17:52:39.668481Z",
     "shell.execute_reply": "2021-05-10T17:52:39.668958Z"
    },
    "papermill": {
     "duration": 2.648881,
     "end_time": "2021-05-10T17:52:39.669142",
     "exception": false,
     "start_time": "2021-05-10T17:52:37.020261",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image512_embeddings_new = find_neighbors(image512_embeddings, n=4).astype(np.half)\n",
    "image512_embeddings_nfnet_new = find_neighbors(image512_embeddings_nfnet, n=4).astype(np.half)\n",
    "bert_embeddings_new = find_neighbors(bert_embeddings, n=4).astype(np.half)\n",
    "sentence_embeddings_new = find_neighbors(sentence_embeddings, n=4).astype(np.half)\n",
    "\n",
    "del image512_embeddings, image512_embeddings_nfnet, bert_embeddings, sentence_embeddings\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T17:52:41.331848Z",
     "iopub.status.busy": "2021-05-10T17:52:41.325829Z",
     "iopub.status.idle": "2021-05-10T17:53:35.266150Z",
     "shell.execute_reply": "2021-05-10T17:53:35.265598Z"
    },
    "papermill": {
     "duration": 54.370501,
     "end_time": "2021-05-10T17:53:35.266301",
     "exception": false,
     "start_time": "2021-05-10T17:52:40.895800",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THR:  -3.3\n",
      "FOUND:  (7786, 8)\n",
      "FOUND:  (5248, 8)\n"
     ]
    }
   ],
   "source": [
    "from functools import reduce\n",
    "\n",
    "thr = -3.3\n",
    "thr_unpopular = -3\n",
    "numb_unpopular = 2\n",
    "thr_popular = -3.4\n",
    "numb_popular = 100\n",
    "CHUNK = 4096\n",
    "    \n",
    "print(\"THR: \", thr)\n",
    "cts = len(bert_embeddings_new) // CHUNK\n",
    "if len(bert_embeddings_new) % CHUNK != 0: \n",
    "    cts += 1\n",
    "\n",
    "result = pd.DataFrame()\n",
    "\n",
    "for i in range(cts):\n",
    "    a = i*CHUNK\n",
    "    b = (i+1)*CHUNK\n",
    "    b = min(b,len(bert_embeddings_new))\n",
    "#         print('chunk',a,'to',b)\n",
    "\n",
    "    dfs = []\n",
    "    for embs, dist_col in zip([image512_embeddings_new, image512_embeddings_nfnet_new,\n",
    "                               text_embeddings, bert_embeddings_new, sentence_embeddings_new],\n",
    "                              FEATURES):\n",
    "#       ####################\n",
    "\n",
    "        model = NearestNeighbors(n_neighbors = KNN_classifier)\n",
    "        model.fit(embs)\n",
    "        distances, indices = model.kneighbors(embs[a:b])\n",
    "\n",
    "        predictions = []\n",
    "        pred_distances = []\n",
    "        numb = CHUNK if b % CHUNK == 0 else b % CHUNK\n",
    "        for k in range(numb):\n",
    "            predictions.append(df['posting_id'].iloc[indices[k,:]].values)\n",
    "            pred_distances.append(distances[k,:])\n",
    "\n",
    "        df_ = df.reset_index().loc[a:b-1]\n",
    "        df_['labels'] = predictions\n",
    "        df_['dists'] = pred_distances\n",
    "        df_markup = cudf.DataFrame({'posting_id':np.repeat(df_.posting_id.values, df_.dists.str.len()),\n",
    "                  'neigh':np.concatenate(df_.labels.values),\n",
    "                  dist_col:np.concatenate(df_.dists.values)})\n",
    "\n",
    "        dfs.append(df_markup[['posting_id', 'neigh', dist_col]].set_index(['posting_id', 'neigh']))\n",
    "\n",
    "    df_final = reduce(lambda left,right: cudf.merge(left, right, left_index=True, right_index=True, how='outer'), dfs)\n",
    "    df_final = df_final.to_pandas().reset_index()\n",
    "\n",
    "    for feat in FEATURES:\n",
    "        df_final[feat] = df_final.groupby('posting_id')[feat].transform(lambda group: group.fillna(group.max()))\n",
    "\n",
    "    df_final[FEATURES] = (df_final[FEATURES] - df_final[FEATURES].mean(0)) / df_final[FEATURES].std(0)\n",
    "    df_final['match'] = cv_coef*df_final[CV].mean(1) + tfidf_coef*df_final[TFIDF].mean(1) + text_coef*df_final[TEXT].mean(1)\n",
    "\n",
    "    bool_unpopular = (df_final[df_final.match<thr].groupby(['posting_id'])['neigh'].count() <= numb_unpopular).values\n",
    "    unpopular_posting_idx = (\n",
    "        df_final[df_final.match<thr]\n",
    "        .groupby(['posting_id'])['neigh']\n",
    "        .count()\n",
    "        .loc[bool_unpopular]\n",
    "        .index.values\n",
    "    )\n",
    "\n",
    "    bool_popular = (df_final[df_final.match<thr].groupby(['posting_id'])['neigh'].count() > numb_popular).values\n",
    "    popular_posting_idx = (\n",
    "        df_final[df_final.match<thr]\n",
    "        .groupby(['posting_id'])['neigh']\n",
    "        .count()\n",
    "        .loc[bool_popular]\n",
    "        .index.values\n",
    "    )\n",
    "\n",
    "    df_pred = df_final[((df_final.posting_id.isin(unpopular_posting_idx)) & (df_final.match < thr_unpopular)) |\n",
    "                       ((df_final.posting_id.isin(popular_posting_idx)) & (df_final.match < thr_popular)) |\n",
    "                       ((~df_final.posting_id.isin(unpopular_posting_idx)) & (~df_final.posting_id.isin(popular_posting_idx)) & (df_final.match < thr))]#.reset_index()\n",
    "\n",
    "    print(\"FOUND: \", df_pred.shape)\n",
    "\n",
    "    df_pred = df_pred[['posting_id', 'neigh']]#.to_pandas()\n",
    "\n",
    "    tmp = df_pred.groupby(['posting_id'])['neigh'].unique().to_dict()\n",
    "\n",
    "    tmp = df_pred.groupby(['posting_id'])['neigh'].unique().to_dict()\n",
    "    df_pred['pred_matches'] = df_pred['posting_id'].map(tmp)\n",
    "    df_pred['pred_matches'] = df_pred['pred_matches'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "    df_pred = df_pred[['posting_id', 'pred_matches']].drop_duplicates()\n",
    "\n",
    "    result = pd.concat([result, df_pred], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T17:53:49.367181Z",
     "iopub.status.busy": "2021-05-10T17:53:49.366093Z",
     "iopub.status.idle": "2021-05-10T17:53:49.653454Z",
     "shell.execute_reply": "2021-05-10T17:53:49.652877Z"
    },
    "papermill": {
     "duration": 0.722372,
     "end_time": "2021-05-10T17:53:49.653592",
     "exception": false,
     "start_time": "2021-05-10T17:53:48.931220",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our final f1 cv score is 0.9019032518163933\n",
      "Our final recall cv score is 0.9988877302745915\n",
      "Our final precision cv score is 0.8579723597570302\n"
     ]
    }
   ],
   "source": [
    "if GET_CV:\n",
    "    result = pd.merge(result, df[['posting_id','matches']], on='posting_id', how='inner')\n",
    "    result['f1'] = f1_score(result['matches'], result['pred_matches'])\n",
    "    result['recall'] = recall_score(result['matches'], result['pred_matches'])\n",
    "    result['precision'] = prec_score(result['matches'], result['pred_matches'])\n",
    "    score = result['f1'].mean()\n",
    "    print(f'Our final f1 cv score is {score}')\n",
    "    score = result['recall'].mean()\n",
    "    print(f'Our final recall cv score is {score}')\n",
    "    score = result['precision'].mean()\n",
    "    print(f'Our final precision cv score is {score}')\n",
    "    result['matches'] = result['pred_matches']\n",
    "    result[['posting_id', 'matches']].to_csv('submission.csv', index = False)\n",
    "else:\n",
    "    result = result[['posting_id', 'pred_matches']].rename(columns={'pred_matches': 'matches'})\n",
    "    result.to_csv('submission.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 465.266965,
   "end_time": "2021-05-10T17:53:55.542213",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-05-10T17:46:10.275248",
   "version": "2.2.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
